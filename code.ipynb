{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3809e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "from options.train_options import TrainOptions\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "from pytorch_fid import fid_score\n",
    "from options.test_options import TestOptions\n",
    "from util.visualizer import save_images\n",
    "from itertools import islice\n",
    "from util import html\n",
    "from options.base_options import BaseOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6713276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe7297",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4de48d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['ipykernel_launcher.py', '--dataroot', './datasets/maps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad294cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument for training\n",
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self, parser):\n",
    "        BaseOptions.initialize(self, parser)\n",
    "        parser.add_argument('--display_freq', type=int, default=400, help='frequency of showing training results on screen')\n",
    "        parser.add_argument('--display_ncols', type=int, default=4, help='if positive, display all images in a single visdom web panel with certain number of images per row.')\n",
    "        parser.add_argument('--display_id', type=int, default=1, help='window id of the web display')\n",
    "        parser.add_argument('--display_port', type=int, default=8097, help='visdom display port')\n",
    "        parser.add_argument('--display_env', type=str, default='main', help='visdom display environment name (default is \"main\")')\n",
    "        parser.add_argument('--display_server', type=str, default=\"http://localhost\", help='visdom server of the web display')\n",
    "        parser.add_argument('--update_html_freq', type=int, default=4000, help='frequency of saving training results to html')\n",
    "        parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
    "        parser.add_argument('--save_latest_freq', type=int, default=10000, help='frequency of saving the latest results')\n",
    "        parser.add_argument('--save_epoch_freq', type=int, default=5, help='frequency of saving checkpoints at the end of epochs')\n",
    "        parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
    "        parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n",
    "        parser.add_argument('--gan_mode', type=str, default='lsgan', help='the type of GAN objective. [vanilla | lsgan ï½œ wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.')\n",
    "        # training parameters\n",
    "        parser.add_argument('--niter', type=int, default=20, help='# of iter at starting learning rate')\n",
    "        parser.add_argument('--niter_decay', type=int, default=20, help='# of iter to linearly decay learning rate to zero')\n",
    "        parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n",
    "        parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "        parser.add_argument('--lr_policy', type=str, default='linear', help='learning rate policy: linear | step | plateau | cosine')\n",
    "        parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "        parser.add_argument('--lr_decay_iters', type=int, default=100, help='multiply by a gamma every lr_decay_iters iterations')\n",
    "        # lambda parameters\n",
    "        parser.add_argument('--lambda_L1', type=float, default=10.0, help='weight for |B-G(A, E(B))|')\n",
    "        parser.add_argument('--lambda_GAN', type=float, default=1.0, help='weight on D loss. D(G(A, E(B)))')\n",
    "        parser.add_argument('--lambda_GAN2', type=float, default=1.0, help='weight on D2 loss, D(G(A, random_z))')\n",
    "        parser.add_argument('--lambda_z', type=float, default=0.5, help='weight for ||E(G(random_z)) - random_z||')\n",
    "        parser.add_argument('--lambda_kl', type=float, default=0.01, help='weight for KL loss')\n",
    "        parser.add_argument('--use_same_D', action='store_true', help='if two Ds share the weights or not')\n",
    "        self.isTrain = True\n",
    "        return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9ca7c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 2                             \n",
      "                    beta1: 0.5                           \n",
      "              center_crop: False                         \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "            conditional_D: False                         \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/maps               \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               lambda_GAN: 1.0                           \n",
      "              lambda_GAN2: 1.0                           \n",
      "                lambda_L1: 10.0                          \n",
      "                lambda_kl: 0.01                          \n",
      "                 lambda_z: 0.5                           \n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 100                           \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: bicycle_gan                   \n",
      "                     name:                               \n",
      "                      ndf: 64                            \n",
      "                      nef: 64                            \n",
      "                     netD: basic_256_multi               \n",
      "                    netD2: basic_256_multi               \n",
      "                     netE: resnet_256                    \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "                    niter: 20                            \n",
      "              niter_decay: 20                            \n",
      "                       nl: relu                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "                   num_Ds: 2                             \n",
      "              num_threads: 4                             \n",
      "                       nz: 8                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 10000                         \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 4000                          \n",
      "                 upsample: basic                         \n",
      "              use_dropout: False                         \n",
      "               use_same_D: False                         \n",
      "                  verbose: False                         \n",
      "                where_add: all                           \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['ipykernel_launcher.py', '--dataroot', './datasets/maps','--model', 'bicycle_gan'] # pix2pix\n",
    "opt = TrainOptions().parse()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2687cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import torch\n",
    "\n",
    "def create_dataset(opt):\n",
    "    \"\"\"Create and return a dataset loader.\"\"\"\n",
    "    # Import the dataset module based on the dataset_name provided in opt\n",
    "    dataset_filename = \"data.\" + opt.dataset_mode + \"_dataset\"\n",
    "    datasetlib = importlib.import_module(dataset_filename)\n",
    "\n",
    "    # Find the dataset class in the module, which should be a subclass of BaseDataset\n",
    "    target_dataset_name = opt.dataset_mode.replace('_', '') + 'dataset'\n",
    "    dataset_class = None\n",
    "    for name, cls in datasetlib.__dict__.items():\n",
    "        if name.lower() == target_dataset_name.lower():\n",
    "            dataset_class = cls\n",
    "            break\n",
    "            \n",
    "    # Create an instance of the dataset\n",
    "    dataset = dataset_class(opt)\n",
    "    print(\"Dataset [%s] was created\" % type(dataset).__name__)\n",
    "\n",
    "    # Create a multi-threaded data loader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=opt.batch_size,\n",
    "        shuffle=not opt.serial_batches,\n",
    "        num_workers=int(opt.num_threads))\n",
    "\n",
    "    # Encapsulate the dataset and dataloader in an object that can be iterated\n",
    "    class DatasetLoader:\n",
    "        def __init__(self, dataset, dataloader):\n",
    "            self.dataset = dataset\n",
    "            self.dataloader = dataloader\n",
    "\n",
    "        def __len__(self):\n",
    "            return min(len(self.dataset), opt.max_dataset_size)\n",
    "\n",
    "        def __iter__(self):\n",
    "            for i, data in enumerate(self.dataloader):\n",
    "                if i * opt.batch_size >= opt.max_dataset_size:\n",
    "                    break\n",
    "                yield data\n",
    "\n",
    "    return DatasetLoader(dataset, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee02ff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset [AlignedDataset] was created\n",
      "The number of training images = 1096\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(opt)  \n",
    "dataset_size = len(dataset)    \n",
    "print('The number of training images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf6fe1",
   "metadata": {},
   "source": [
    "## BicycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4223ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.base_model import BaseModel\n",
    "from models import networks\n",
    "\n",
    "class BiCycleGANModel(BaseModel):\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train=True):\n",
    "        return parser\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        if opt.isTrain:\n",
    "            assert opt.batch_size % 2 == 0  # load two images at one time.\n",
    "\n",
    "        BaseModel.__init__(self, opt)\n",
    "        # specify the training losses you want to print out. The program will call base_model.get_current_losses\n",
    "        self.loss_names = ['G_GAN', 'D', 'G_GAN2', 'D2', 'G_L1', 'z_L1', 'kl']\n",
    "        # specify the images you want to save/display. The program will call base_model.get_current_visuals\n",
    "        self.visual_names = ['real_A_encoded', 'real_B_encoded', 'fake_B_random', 'fake_B_encoded']\n",
    "        # specify the models you want to save to the disk. The program will call base_model.save_networks and base_model.load_networks\n",
    "        use_D = opt.isTrain and opt.lambda_GAN > 0.0\n",
    "        use_D2 = opt.isTrain and opt.lambda_GAN2 > 0.0 and not opt.use_same_D\n",
    "        use_E = opt.isTrain or not opt.no_encode\n",
    "        use_vae = True\n",
    "        self.model_names = ['G']\n",
    "        self.netG = networks.define_G(opt.input_nc, opt.output_nc, opt.nz, opt.ngf, netG=opt.netG,\n",
    "                                      norm=opt.norm, nl=opt.nl, use_dropout=opt.use_dropout, init_type=opt.init_type, init_gain=opt.init_gain,\n",
    "                                      gpu_ids=self.gpu_ids, where_add=opt.where_add, upsample=opt.upsample)\n",
    "        D_output_nc = opt.input_nc + opt.output_nc if opt.conditional_D else opt.output_nc\n",
    "        if use_D:\n",
    "            self.model_names += ['D']\n",
    "            self.netD = networks.define_D(D_output_nc, opt.ndf, netD=opt.netD, norm=opt.norm, nl=opt.nl,\n",
    "                                          init_type=opt.init_type, init_gain=opt.init_gain, num_Ds=opt.num_Ds, gpu_ids=self.gpu_ids)\n",
    "        if use_D2:\n",
    "            self.model_names += ['D2']\n",
    "            self.netD2 = networks.define_D(D_output_nc, opt.ndf, netD=opt.netD2, norm=opt.norm, nl=opt.nl,\n",
    "                                           init_type=opt.init_type, init_gain=opt.init_gain, num_Ds=opt.num_Ds, gpu_ids=self.gpu_ids)\n",
    "        else:\n",
    "            self.netD2 = None\n",
    "        if use_E:\n",
    "            self.model_names += ['E']\n",
    "            self.netE = networks.define_E(opt.output_nc, opt.nz, opt.nef, netE=opt.netE, norm=opt.norm, nl=opt.nl,\n",
    "                                          init_type=opt.init_type, init_gain=opt.init_gain, gpu_ids=self.gpu_ids, vaeLike=use_vae)\n",
    "\n",
    "        if opt.isTrain:\n",
    "            self.criterionGAN = networks.GANLoss(gan_mode=opt.gan_mode).to(self.device)\n",
    "            self.criterionL1 = torch.nn.L1Loss()\n",
    "            self.criterionZ = torch.nn.L1Loss()\n",
    "            # initialize optimizers\n",
    "            self.optimizers = []\n",
    "            self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizers.append(self.optimizer_G)\n",
    "            if use_E:\n",
    "                self.optimizer_E = torch.optim.Adam(self.netE.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "                self.optimizers.append(self.optimizer_E)\n",
    "\n",
    "            if use_D:\n",
    "                self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "                self.optimizers.append(self.optimizer_D)\n",
    "            if use_D2:\n",
    "                self.optimizer_D2 = torch.optim.Adam(self.netD2.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "                self.optimizers.append(self.optimizer_D2)\n",
    "\n",
    "    def is_train(self):\n",
    "        \"\"\"check if the current batch is good for training.\"\"\"\n",
    "        return self.opt.isTrain and self.real_A.size(0) == self.opt.batch_size\n",
    "\n",
    "    def set_input(self, input):\n",
    "        AtoB = self.opt.direction == 'AtoB'\n",
    "        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
    "        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n",
    "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
    "\n",
    "    def get_z_random(self, batch_size, nz, random_type='gauss'):\n",
    "        if random_type == 'uni':\n",
    "            z = torch.rand(batch_size, nz) * 2.0 - 1.0\n",
    "        elif random_type == 'gauss':\n",
    "            z = torch.randn(batch_size, nz)\n",
    "        return z.detach().to(self.device)\n",
    "\n",
    "    def encode(self, input_image):\n",
    "        mu, logvar = self.netE.forward(input_image)\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = self.get_z_random(std.size(0), std.size(1))\n",
    "        z = eps.mul(std).add_(mu)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def test(self, z0=None, encode=False):\n",
    "        with torch.no_grad():\n",
    "            if encode:  # use encoded z\n",
    "                z0, _ = self.netE(self.real_B)\n",
    "            if z0 is None:\n",
    "                z0 = self.get_z_random(self.real_A.size(0), self.opt.nz)\n",
    "            self.fake_B = self.netG(self.real_A, z0)\n",
    "            return self.real_A, self.fake_B, self.real_B\n",
    "\n",
    "    def forward(self):\n",
    "        # get real images\n",
    "        half_size = self.opt.batch_size // 2\n",
    "        # A1, B1 for encoded; A2, B2 for random\n",
    "        self.real_A_encoded = self.real_A[0:half_size]\n",
    "        self.real_B_encoded = self.real_B[0:half_size]\n",
    "        self.real_A_random = self.real_A[half_size:]\n",
    "        self.real_B_random = self.real_B[half_size:]\n",
    "        # get encoded z\n",
    "        self.z_encoded, self.mu, self.logvar = self.encode(self.real_B_encoded)\n",
    "        # get random z\n",
    "        self.z_random = self.get_z_random(self.real_A_encoded.size(0), self.opt.nz)\n",
    "        # generate fake_B_encoded\n",
    "        self.fake_B_encoded = self.netG(self.real_A_encoded, self.z_encoded)\n",
    "        # generate fake_B_random\n",
    "        self.fake_B_random = self.netG(self.real_A_encoded, self.z_random)\n",
    "        if self.opt.conditional_D:   # tedious conditoinal data\n",
    "            self.fake_data_encoded = torch.cat([self.real_A_encoded, self.fake_B_encoded], 1)\n",
    "            self.real_data_encoded = torch.cat([self.real_A_encoded, self.real_B_encoded], 1)\n",
    "            self.fake_data_random = torch.cat([self.real_A_encoded, self.fake_B_random], 1)\n",
    "            self.real_data_random = torch.cat([self.real_A_random, self.real_B_random], 1)\n",
    "        else:\n",
    "            self.fake_data_encoded = self.fake_B_encoded\n",
    "            self.fake_data_random = self.fake_B_random\n",
    "            self.real_data_encoded = self.real_B_encoded\n",
    "            self.real_data_random = self.real_B_random\n",
    "\n",
    "        # compute z_predict\n",
    "        if self.opt.lambda_z > 0.0:\n",
    "            self.mu2, logvar2 = self.netE(self.fake_B_random)  # mu2 is a point estimate\n",
    "\n",
    "    def backward_D(self, netD, real, fake):\n",
    "        # Fake, stop backprop to the generator by detaching fake_B\n",
    "        pred_fake = netD(fake.detach())\n",
    "        # real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_fake, _ = self.criterionGAN(pred_fake, False)\n",
    "        loss_D_real, _ = self.criterionGAN(pred_real, True)\n",
    "        # Combined loss\n",
    "        loss_D = loss_D_fake + loss_D_real\n",
    "        loss_D.backward()\n",
    "        return loss_D, [loss_D_fake, loss_D_real]\n",
    "\n",
    "    def backward_G_GAN(self, fake, netD=None, ll=0.0):\n",
    "        if ll > 0.0:\n",
    "            pred_fake = netD(fake)\n",
    "            loss_G_GAN, _ = self.criterionGAN(pred_fake, True)\n",
    "        else:\n",
    "            loss_G_GAN = 0\n",
    "        return loss_G_GAN * ll\n",
    "\n",
    "    def backward_EG(self):\n",
    "        # 1, G(A) should fool D\n",
    "        self.loss_G_GAN = self.backward_G_GAN(self.fake_data_encoded, self.netD, self.opt.lambda_GAN)\n",
    "        if self.opt.use_same_D:\n",
    "            self.loss_G_GAN2 = self.backward_G_GAN(self.fake_data_random, self.netD, self.opt.lambda_GAN2)\n",
    "        else:\n",
    "            self.loss_G_GAN2 = self.backward_G_GAN(self.fake_data_random, self.netD2, self.opt.lambda_GAN2)\n",
    "        # 2. KL loss\n",
    "        if self.opt.lambda_kl > 0.0:\n",
    "            self.loss_kl = torch.sum(1 + self.logvar - self.mu.pow(2) - self.logvar.exp()) * (-0.5 * self.opt.lambda_kl)\n",
    "        else:\n",
    "            self.loss_kl = 0\n",
    "        # 3, reconstruction |fake_B-real_B|\n",
    "        if self.opt.lambda_L1 > 0.0:\n",
    "            self.loss_G_L1 = self.criterionL1(self.fake_B_encoded, self.real_B_encoded) * self.opt.lambda_L1\n",
    "        else:\n",
    "            self.loss_G_L1 = 0.0\n",
    "\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_GAN2 + self.loss_G_L1 + self.loss_kl\n",
    "        self.loss_G.backward(retain_graph=True)\n",
    "\n",
    "    def update_D(self):\n",
    "        self.set_requires_grad([self.netD, self.netD2], True)\n",
    "        # update D1\n",
    "        if self.opt.lambda_GAN > 0.0:\n",
    "            self.optimizer_D.zero_grad()\n",
    "            self.loss_D, self.losses_D = self.backward_D(self.netD, self.real_data_encoded, self.fake_data_encoded)\n",
    "            if self.opt.use_same_D:\n",
    "                self.loss_D2, self.losses_D2 = self.backward_D(self.netD, self.real_data_random, self.fake_data_random)\n",
    "            self.optimizer_D.step()\n",
    "\n",
    "        if self.opt.lambda_GAN2 > 0.0 and not self.opt.use_same_D:\n",
    "            self.optimizer_D2.zero_grad()\n",
    "            self.loss_D2, self.losses_D2 = self.backward_D(self.netD2, self.real_data_random, self.fake_data_random)\n",
    "            self.optimizer_D2.step()\n",
    "\n",
    "    def backward_G_alone(self):\n",
    "        # 3, reconstruction |(E(G(A, z_random)))-z_random|\n",
    "        if self.opt.lambda_z > 0.0:\n",
    "            self.loss_z_L1 = self.criterionZ(self.mu2, self.z_random) * self.opt.lambda_z\n",
    "            self.loss_z_L1.backward()\n",
    "        else:\n",
    "            self.loss_z_L1 = 0.0\n",
    "\n",
    "    def update_G_and_E(self):\n",
    "        # update G and E\n",
    "        self.set_requires_grad([self.netD, self.netD2], False)\n",
    "        self.optimizer_E.zero_grad()\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_EG()\n",
    "\n",
    "        # update G alone\n",
    "        if self.opt.lambda_z > 0.0:\n",
    "            self.set_requires_grad([self.netE], False)\n",
    "            self.backward_G_alone()\n",
    "            self.set_requires_grad([self.netE], True)\n",
    "\n",
    "        self.optimizer_E.step()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.update_G_and_E()\n",
    "        self.update_D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26387fdc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23dda66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [BiCycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.795 M\n",
      "[Network D] Total number of parameters : 3.459 M\n",
      "[Network D2] Total number of parameters : 3.459 M\n",
      "[Network E] Total number of parameters : 2.590 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints/web...\n",
      "(epoch: 1, iters: 100, time: 0.049, data: 0.793) G_GAN: 0.561 D: 0.700 G_GAN2: 0.732 D2: 1.198 G_L1: 1.111 z_L1: 1.074 kl: 0.101 \n",
      "(epoch: 1, iters: 200, time: 0.042, data: 0.004) G_GAN: 0.759 D: 0.444 G_GAN2: 0.514 D2: 1.041 G_L1: 2.191 z_L1: 0.721 kl: 0.055 \n",
      "(epoch: 1, iters: 300, time: 0.047, data: 0.002) G_GAN: 0.692 D: 1.450 G_GAN2: 0.534 D2: 0.696 G_L1: 2.535 z_L1: 0.516 kl: 0.014 \n",
      "(epoch: 1, iters: 400, time: 0.199, data: 0.005) G_GAN: 0.941 D: 0.848 G_GAN2: 0.872 D2: 1.159 G_L1: 1.294 z_L1: 0.519 kl: 0.021 \n",
      "(epoch: 1, iters: 500, time: 0.041, data: 0.005) G_GAN: 0.636 D: 0.894 G_GAN2: 0.665 D2: 1.347 G_L1: 1.534 z_L1: 0.436 kl: 0.008 \n",
      "(epoch: 1, iters: 600, time: 0.038, data: 0.003) G_GAN: 0.502 D: 1.192 G_GAN2: 0.833 D2: 0.890 G_L1: 1.601 z_L1: 0.578 kl: 0.012 \n",
      "(epoch: 1, iters: 700, time: 0.048, data: 0.002) G_GAN: 0.819 D: 0.616 G_GAN2: 0.630 D2: 0.859 G_L1: 1.400 z_L1: 0.484 kl: 0.004 \n",
      "(epoch: 1, iters: 800, time: 0.178, data: 0.004) G_GAN: 0.608 D: 0.913 G_GAN2: 0.610 D2: 0.759 G_L1: 0.753 z_L1: 0.215 kl: 0.028 \n",
      "(epoch: 1, iters: 900, time: 0.041, data: 0.004) G_GAN: 0.819 D: 1.105 G_GAN2: 0.842 D2: 0.956 G_L1: 0.856 z_L1: 0.435 kl: 0.006 \n",
      "(epoch: 1, iters: 1000, time: 0.047, data: 0.003) G_GAN: 1.470 D: 1.143 G_GAN2: 0.933 D2: 0.669 G_L1: 1.084 z_L1: 0.407 kl: 0.021 \n",
      "End of epoch 1 / 40 \t Time Taken: 60 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 4, time: 0.048, data: 0.003) G_GAN: 0.624 D: 0.978 G_GAN2: 0.667 D2: 0.823 G_L1: 0.931 z_L1: 0.477 kl: 0.018 \n",
      "(epoch: 2, iters: 104, time: 0.197, data: 0.002) G_GAN: 0.562 D: 0.813 G_GAN2: 0.657 D2: 0.806 G_L1: 1.241 z_L1: 0.440 kl: 0.038 \n",
      "(epoch: 2, iters: 204, time: 0.039, data: 0.004) G_GAN: 0.610 D: 0.852 G_GAN2: 0.548 D2: 0.703 G_L1: 0.929 z_L1: 0.456 kl: 0.020 \n",
      "(epoch: 2, iters: 304, time: 0.050, data: 0.002) G_GAN: 0.892 D: 1.089 G_GAN2: 0.864 D2: 0.812 G_L1: 0.807 z_L1: 0.351 kl: 0.033 \n",
      "(epoch: 2, iters: 404, time: 0.057, data: 0.002) G_GAN: 0.997 D: 0.725 G_GAN2: 0.482 D2: 0.988 G_L1: 1.038 z_L1: 0.344 kl: 0.061 \n",
      "(epoch: 2, iters: 504, time: 0.220, data: 0.003) G_GAN: 0.931 D: 0.710 G_GAN2: 0.596 D2: 0.668 G_L1: 0.680 z_L1: 0.475 kl: 0.043 \n",
      "(epoch: 2, iters: 604, time: 0.048, data: 0.002) G_GAN: 0.557 D: 1.015 G_GAN2: 0.682 D2: 0.694 G_L1: 1.684 z_L1: 0.369 kl: 0.008 \n",
      "(epoch: 2, iters: 704, time: 0.050, data: 0.002) G_GAN: 0.953 D: 1.137 G_GAN2: 1.248 D2: 0.861 G_L1: 0.865 z_L1: 0.400 kl: 0.035 \n",
      "(epoch: 2, iters: 804, time: 0.057, data: 0.004) G_GAN: 0.454 D: 1.018 G_GAN2: 0.777 D2: 0.552 G_L1: 1.030 z_L1: 0.459 kl: 0.035 \n",
      "(epoch: 2, iters: 904, time: 0.229, data: 0.002) G_GAN: 0.845 D: 1.020 G_GAN2: 0.805 D2: 0.564 G_L1: 0.874 z_L1: 0.518 kl: 0.032 \n",
      "(epoch: 2, iters: 1004, time: 0.051, data: 0.003) G_GAN: 0.709 D: 0.953 G_GAN2: 0.854 D2: 0.870 G_L1: 0.788 z_L1: 0.440 kl: 0.040 \n",
      "End of epoch 2 / 40 \t Time Taken: 57 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 8, time: 0.051, data: 0.004) G_GAN: 0.491 D: 1.014 G_GAN2: 0.703 D2: 1.044 G_L1: 0.883 z_L1: 0.487 kl: 0.021 \n",
      "(epoch: 3, iters: 108, time: 0.042, data: 0.006) G_GAN: 0.866 D: 1.012 G_GAN2: 1.394 D2: 1.274 G_L1: 0.714 z_L1: 0.408 kl: 0.043 \n",
      "(epoch: 3, iters: 208, time: 0.202, data: 0.003) G_GAN: 0.560 D: 0.953 G_GAN2: 0.639 D2: 1.065 G_L1: 0.670 z_L1: 0.402 kl: 0.040 \n",
      "(epoch: 3, iters: 308, time: 0.047, data: 0.004) G_GAN: 0.371 D: 1.457 G_GAN2: 0.656 D2: 1.166 G_L1: 1.322 z_L1: 0.517 kl: 0.040 \n",
      "(epoch: 3, iters: 408, time: 0.045, data: 0.003) G_GAN: 0.502 D: 0.897 G_GAN2: 0.346 D2: 1.062 G_L1: 0.815 z_L1: 0.237 kl: 0.028 \n",
      "(epoch: 3, iters: 508, time: 0.044, data: 0.003) G_GAN: 0.528 D: 0.796 G_GAN2: 0.714 D2: 0.812 G_L1: 1.755 z_L1: 0.413 kl: 0.057 \n",
      "(epoch: 3, iters: 608, time: 0.177, data: 0.003) G_GAN: 0.559 D: 0.911 G_GAN2: 0.631 D2: 0.806 G_L1: 2.297 z_L1: 0.524 kl: 0.025 \n",
      "(epoch: 3, iters: 708, time: 0.044, data: 0.004) G_GAN: 0.721 D: 1.346 G_GAN2: 0.827 D2: 0.743 G_L1: 1.631 z_L1: 0.381 kl: 0.047 \n",
      "(epoch: 3, iters: 808, time: 0.054, data: 0.004) G_GAN: 0.766 D: 1.099 G_GAN2: 0.581 D2: 0.811 G_L1: 0.857 z_L1: 0.479 kl: 0.037 \n",
      "(epoch: 3, iters: 908, time: 0.044, data: 0.004) G_GAN: 0.647 D: 0.765 G_GAN2: 0.284 D2: 1.101 G_L1: 0.920 z_L1: 0.445 kl: 0.028 \n",
      "(epoch: 3, iters: 1008, time: 0.151, data: 0.003) G_GAN: 1.104 D: 0.479 G_GAN2: 0.395 D2: 0.900 G_L1: 1.897 z_L1: 0.316 kl: 0.063 \n",
      "End of epoch 3 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 12, time: 0.047, data: 0.002) G_GAN: 0.880 D: 0.991 G_GAN2: 0.955 D2: 1.147 G_L1: 0.998 z_L1: 0.441 kl: 0.040 \n",
      "(epoch: 4, iters: 112, time: 0.048, data: 0.002) G_GAN: 0.639 D: 1.711 G_GAN2: 0.965 D2: 0.692 G_L1: 1.527 z_L1: 0.375 kl: 0.051 \n",
      "(epoch: 4, iters: 212, time: 0.044, data: 0.003) G_GAN: 0.646 D: 0.675 G_GAN2: 0.541 D2: 0.795 G_L1: 0.950 z_L1: 0.588 kl: 0.020 \n",
      "(epoch: 4, iters: 312, time: 0.195, data: 0.003) G_GAN: 1.060 D: 0.352 G_GAN2: 0.483 D2: 0.951 G_L1: 2.758 z_L1: 0.294 kl: 0.020 \n",
      "(epoch: 4, iters: 412, time: 0.044, data: 0.004) G_GAN: 0.675 D: 1.044 G_GAN2: 0.748 D2: 1.001 G_L1: 0.724 z_L1: 0.532 kl: 0.042 \n",
      "(epoch: 4, iters: 512, time: 0.044, data: 0.003) G_GAN: 1.027 D: 0.843 G_GAN2: 1.216 D2: 1.434 G_L1: 0.749 z_L1: 0.336 kl: 0.035 \n",
      "(epoch: 4, iters: 612, time: 0.044, data: 0.002) G_GAN: 0.914 D: 0.789 G_GAN2: 1.107 D2: 0.697 G_L1: 1.168 z_L1: 0.413 kl: 0.031 \n",
      "(epoch: 4, iters: 712, time: 0.206, data: 0.002) G_GAN: 1.722 D: 0.668 G_GAN2: 0.638 D2: 0.537 G_L1: 0.720 z_L1: 0.212 kl: 0.029 \n",
      "(epoch: 4, iters: 812, time: 0.043, data: 0.004) G_GAN: 0.739 D: 0.771 G_GAN2: 0.710 D2: 0.730 G_L1: 1.064 z_L1: 0.617 kl: 0.049 \n",
      "(epoch: 4, iters: 912, time: 0.052, data: 0.002) G_GAN: 1.116 D: 0.790 G_GAN2: 1.243 D2: 0.533 G_L1: 0.680 z_L1: 0.527 kl: 0.023 \n",
      "(epoch: 4, iters: 1012, time: 0.046, data: 0.002) G_GAN: 0.571 D: 0.993 G_GAN2: 0.726 D2: 0.794 G_L1: 1.022 z_L1: 0.539 kl: 0.035 \n",
      "End of epoch 4 / 40 \t Time Taken: 50 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 16, time: 0.202, data: 0.002) G_GAN: 0.741 D: 0.858 G_GAN2: 0.628 D2: 1.090 G_L1: 0.886 z_L1: 0.295 kl: 0.017 \n",
      "(epoch: 5, iters: 116, time: 0.043, data: 0.004) G_GAN: 0.674 D: 0.906 G_GAN2: 0.961 D2: 1.155 G_L1: 0.874 z_L1: 0.404 kl: 0.020 \n",
      "(epoch: 5, iters: 216, time: 0.049, data: 0.002) G_GAN: 0.667 D: 0.777 G_GAN2: 0.729 D2: 0.974 G_L1: 0.806 z_L1: 0.416 kl: 0.019 \n",
      "(epoch: 5, iters: 316, time: 0.043, data: 0.003) G_GAN: 0.944 D: 1.088 G_GAN2: 0.505 D2: 1.400 G_L1: 2.002 z_L1: 0.549 kl: 0.029 \n",
      "(epoch: 5, iters: 416, time: 0.186, data: 0.002) G_GAN: 0.575 D: 0.858 G_GAN2: 0.706 D2: 0.646 G_L1: 2.144 z_L1: 0.382 kl: 0.027 \n",
      "(epoch: 5, iters: 516, time: 0.058, data: 0.007) G_GAN: 1.135 D: 0.927 G_GAN2: 0.595 D2: 0.584 G_L1: 0.800 z_L1: 0.497 kl: 0.025 \n",
      "(epoch: 5, iters: 616, time: 0.045, data: 0.004) G_GAN: 0.659 D: 0.904 G_GAN2: 0.680 D2: 0.674 G_L1: 2.170 z_L1: 0.375 kl: 0.015 \n",
      "(epoch: 5, iters: 716, time: 0.065, data: 0.004) G_GAN: 0.646 D: 0.641 G_GAN2: 0.453 D2: 0.909 G_L1: 1.021 z_L1: 0.507 kl: 0.088 \n",
      "(epoch: 5, iters: 816, time: 0.168, data: 0.004) G_GAN: 0.714 D: 1.049 G_GAN2: 0.691 D2: 1.588 G_L1: 1.201 z_L1: 0.409 kl: 0.016 \n",
      "(epoch: 5, iters: 916, time: 0.044, data: 0.004) G_GAN: 0.908 D: 0.673 G_GAN2: 0.230 D2: 1.229 G_L1: 1.035 z_L1: 0.464 kl: 0.032 \n",
      "(epoch: 5, iters: 1016, time: 0.046, data: 0.003) G_GAN: 0.752 D: 0.519 G_GAN2: 0.691 D2: 0.650 G_L1: 2.186 z_L1: 0.489 kl: 0.013 \n",
      "saving the model at the end of epoch 5, iters 5480\n",
      "End of epoch 5 / 40 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 20, time: 0.050, data: 0.003) G_GAN: 0.279 D: 1.742 G_GAN2: 0.760 D2: 0.971 G_L1: 1.403 z_L1: 0.468 kl: 0.041 \n",
      "(epoch: 6, iters: 120, time: 0.212, data: 0.004) G_GAN: 1.454 D: 0.394 G_GAN2: 1.110 D2: 0.775 G_L1: 1.813 z_L1: 0.433 kl: 0.028 \n",
      "(epoch: 6, iters: 220, time: 0.042, data: 0.003) G_GAN: 1.363 D: 0.775 G_GAN2: 1.076 D2: 0.895 G_L1: 0.920 z_L1: 0.410 kl: 0.017 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 6, iters: 320, time: 0.050, data: 0.003) G_GAN: 0.676 D: 0.494 G_GAN2: 0.684 D2: 0.567 G_L1: 2.043 z_L1: 0.363 kl: 0.030 \n",
      "(epoch: 6, iters: 420, time: 0.048, data: 0.003) G_GAN: 0.868 D: 0.746 G_GAN2: 0.502 D2: 0.963 G_L1: 0.781 z_L1: 0.294 kl: 0.025 \n",
      "(epoch: 6, iters: 520, time: 0.178, data: 0.003) G_GAN: 1.187 D: 1.188 G_GAN2: 0.941 D2: 1.848 G_L1: 0.522 z_L1: 0.312 kl: 0.027 \n",
      "(epoch: 6, iters: 620, time: 0.043, data: 0.004) G_GAN: 1.097 D: 0.875 G_GAN2: 1.060 D2: 1.065 G_L1: 1.546 z_L1: 0.401 kl: 0.117 \n",
      "(epoch: 6, iters: 720, time: 0.044, data: 0.002) G_GAN: 1.078 D: 0.377 G_GAN2: 0.737 D2: 0.498 G_L1: 1.692 z_L1: 0.353 kl: 0.033 \n",
      "(epoch: 6, iters: 820, time: 0.044, data: 0.003) G_GAN: 1.048 D: 0.944 G_GAN2: 0.608 D2: 0.907 G_L1: 0.935 z_L1: 0.380 kl: 0.024 \n",
      "(epoch: 6, iters: 920, time: 0.204, data: 0.003) G_GAN: 1.030 D: 0.636 G_GAN2: 0.498 D2: 0.722 G_L1: 0.915 z_L1: 0.792 kl: 0.050 \n",
      "(epoch: 6, iters: 1020, time: 0.049, data: 0.004) G_GAN: 0.731 D: 0.763 G_GAN2: 0.608 D2: 0.879 G_L1: 1.355 z_L1: 0.468 kl: 0.050 \n",
      "End of epoch 6 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 24, time: 0.044, data: 0.003) G_GAN: 0.735 D: 0.637 G_GAN2: 0.643 D2: 0.806 G_L1: 1.842 z_L1: 0.470 kl: 0.032 \n",
      "(epoch: 7, iters: 124, time: 0.048, data: 0.002) G_GAN: 0.881 D: 0.589 G_GAN2: 0.943 D2: 0.364 G_L1: 0.757 z_L1: 0.423 kl: 0.032 \n",
      "(epoch: 7, iters: 224, time: 0.185, data: 0.003) G_GAN: 0.650 D: 0.756 G_GAN2: 2.031 D2: 1.417 G_L1: 0.962 z_L1: 0.286 kl: 0.127 \n",
      "(epoch: 7, iters: 324, time: 0.042, data: 0.003) G_GAN: 0.951 D: 0.643 G_GAN2: 0.984 D2: 0.602 G_L1: 1.957 z_L1: 0.501 kl: 0.017 \n",
      "(epoch: 7, iters: 424, time: 0.050, data: 0.003) G_GAN: 1.291 D: 0.496 G_GAN2: 0.912 D2: 0.341 G_L1: 0.771 z_L1: 0.529 kl: 0.030 \n",
      "(epoch: 7, iters: 524, time: 0.046, data: 0.002) G_GAN: 0.866 D: 0.879 G_GAN2: 0.989 D2: 0.988 G_L1: 0.941 z_L1: 0.551 kl: 0.019 \n",
      "(epoch: 7, iters: 624, time: 0.174, data: 0.003) G_GAN: 0.890 D: 0.722 G_GAN2: 0.896 D2: 0.419 G_L1: 1.158 z_L1: 0.436 kl: 0.110 \n",
      "(epoch: 7, iters: 724, time: 0.048, data: 0.004) G_GAN: 0.678 D: 1.052 G_GAN2: 1.054 D2: 0.462 G_L1: 1.029 z_L1: 0.394 kl: 0.021 \n",
      "(epoch: 7, iters: 824, time: 0.042, data: 0.003) G_GAN: 1.069 D: 0.298 G_GAN2: 0.469 D2: 0.658 G_L1: 1.430 z_L1: 0.303 kl: 0.031 \n",
      "(epoch: 7, iters: 924, time: 0.047, data: 0.002) G_GAN: 0.896 D: 0.703 G_GAN2: 0.677 D2: 1.184 G_L1: 1.553 z_L1: 0.542 kl: 0.035 \n",
      "(epoch: 7, iters: 1024, time: 0.191, data: 0.001) G_GAN: 0.460 D: 1.124 G_GAN2: 0.873 D2: 1.299 G_L1: 1.984 z_L1: 0.522 kl: 0.033 \n",
      "End of epoch 7 / 40 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 28, time: 0.045, data: 0.004) G_GAN: 0.889 D: 0.865 G_GAN2: 1.206 D2: 1.478 G_L1: 1.024 z_L1: 0.415 kl: 0.069 \n",
      "(epoch: 8, iters: 128, time: 0.049, data: 0.002) G_GAN: 0.856 D: 1.104 G_GAN2: 1.053 D2: 0.894 G_L1: 1.128 z_L1: 0.599 kl: 0.019 \n",
      "(epoch: 8, iters: 228, time: 0.043, data: 0.003) G_GAN: 0.621 D: 0.807 G_GAN2: 0.657 D2: 0.626 G_L1: 1.829 z_L1: 0.330 kl: 0.019 \n",
      "(epoch: 8, iters: 328, time: 0.218, data: 0.002) G_GAN: 1.180 D: 0.624 G_GAN2: 0.896 D2: 0.539 G_L1: 0.838 z_L1: 0.409 kl: 0.024 \n",
      "(epoch: 8, iters: 428, time: 0.048, data: 0.003) G_GAN: 0.611 D: 0.569 G_GAN2: 0.426 D2: 0.656 G_L1: 1.737 z_L1: 0.392 kl: 0.046 \n",
      "(epoch: 8, iters: 528, time: 0.042, data: 0.003) G_GAN: 0.798 D: 0.956 G_GAN2: 1.226 D2: 0.917 G_L1: 1.502 z_L1: 0.378 kl: 0.012 \n",
      "(epoch: 8, iters: 628, time: 0.048, data: 0.002) G_GAN: 0.948 D: 0.384 G_GAN2: 1.565 D2: 0.157 G_L1: 1.040 z_L1: 0.369 kl: 0.042 \n",
      "(epoch: 8, iters: 728, time: 0.196, data: 0.004) G_GAN: 0.513 D: 0.961 G_GAN2: 0.613 D2: 0.813 G_L1: 1.623 z_L1: 0.321 kl: 0.034 \n",
      "(epoch: 8, iters: 828, time: 0.047, data: 0.003) G_GAN: 1.166 D: 0.766 G_GAN2: 1.805 D2: 1.378 G_L1: 0.997 z_L1: 0.599 kl: 0.027 \n",
      "(epoch: 8, iters: 928, time: 0.049, data: 0.003) G_GAN: 0.766 D: 0.486 G_GAN2: 0.610 D2: 0.754 G_L1: 1.578 z_L1: 0.444 kl: 0.065 \n",
      "(epoch: 8, iters: 1028, time: 0.052, data: 0.002) G_GAN: 0.843 D: 0.776 G_GAN2: 0.532 D2: 0.900 G_L1: 0.999 z_L1: 0.440 kl: 0.011 \n",
      "End of epoch 8 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 32, time: 0.212, data: 0.002) G_GAN: 0.850 D: 0.549 G_GAN2: 0.440 D2: 1.198 G_L1: 1.253 z_L1: 0.402 kl: 0.021 \n",
      "(epoch: 9, iters: 132, time: 0.049, data: 0.003) G_GAN: 0.981 D: 0.708 G_GAN2: 0.843 D2: 0.510 G_L1: 1.190 z_L1: 0.424 kl: 0.076 \n",
      "(epoch: 9, iters: 232, time: 0.045, data: 0.002) G_GAN: 1.299 D: 1.088 G_GAN2: 1.452 D2: 0.504 G_L1: 0.992 z_L1: 0.536 kl: 0.031 \n",
      "(epoch: 9, iters: 332, time: 0.044, data: 0.002) G_GAN: 0.683 D: 0.530 G_GAN2: 1.018 D2: 0.300 G_L1: 1.371 z_L1: 0.517 kl: 0.076 \n",
      "(epoch: 9, iters: 432, time: 0.189, data: 0.001) G_GAN: 0.767 D: 0.445 G_GAN2: 0.862 D2: 0.294 G_L1: 1.870 z_L1: 0.468 kl: 0.025 \n",
      "(epoch: 9, iters: 532, time: 0.053, data: 0.005) G_GAN: 1.010 D: 0.713 G_GAN2: 0.446 D2: 0.616 G_L1: 0.872 z_L1: 0.426 kl: 0.016 \n",
      "(epoch: 9, iters: 632, time: 0.049, data: 0.003) G_GAN: 1.137 D: 0.987 G_GAN2: 0.808 D2: 0.349 G_L1: 0.729 z_L1: 0.332 kl: 0.029 \n",
      "(epoch: 9, iters: 732, time: 0.048, data: 0.003) G_GAN: 1.435 D: 0.904 G_GAN2: 1.346 D2: 0.205 G_L1: 1.461 z_L1: 0.418 kl: 0.067 \n",
      "(epoch: 9, iters: 832, time: 0.214, data: 0.002) G_GAN: 1.008 D: 0.321 G_GAN2: 0.873 D2: 0.322 G_L1: 1.042 z_L1: 0.158 kl: 0.021 \n",
      "(epoch: 9, iters: 932, time: 0.045, data: 0.003) G_GAN: 1.618 D: 0.434 G_GAN2: 0.622 D2: 0.540 G_L1: 1.602 z_L1: 0.538 kl: 0.027 \n",
      "(epoch: 9, iters: 1032, time: 0.049, data: 0.002) G_GAN: 0.579 D: 0.922 G_GAN2: 0.836 D2: 0.508 G_L1: 2.213 z_L1: 0.494 kl: 0.023 \n",
      "End of epoch 9 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 36, time: 0.048, data: 0.003) G_GAN: 0.913 D: 1.141 G_GAN2: 0.355 D2: 0.859 G_L1: 0.810 z_L1: 0.442 kl: 0.034 \n",
      "(epoch: 10, iters: 136, time: 0.177, data: 0.002) G_GAN: 1.118 D: 0.750 G_GAN2: 0.743 D2: 0.515 G_L1: 1.407 z_L1: 0.422 kl: 0.028 \n",
      "saving the latest model (epoch 10, total_iters 10000)\n",
      "(epoch: 10, iters: 236, time: 0.047, data: 0.002) G_GAN: 0.750 D: 0.535 G_GAN2: 1.096 D2: 0.855 G_L1: 0.839 z_L1: 0.561 kl: 0.099 \n",
      "(epoch: 10, iters: 336, time: 0.046, data: 0.006) G_GAN: 0.629 D: 0.732 G_GAN2: 0.945 D2: 0.412 G_L1: 1.193 z_L1: 0.710 kl: 0.037 \n",
      "(epoch: 10, iters: 436, time: 0.045, data: 0.002) G_GAN: 1.649 D: 1.071 G_GAN2: 1.343 D2: 1.588 G_L1: 0.784 z_L1: 0.392 kl: 0.028 \n",
      "(epoch: 10, iters: 536, time: 0.229, data: 0.002) G_GAN: 1.181 D: 0.323 G_GAN2: 0.433 D2: 0.960 G_L1: 1.324 z_L1: 0.597 kl: 0.045 \n",
      "(epoch: 10, iters: 636, time: 0.043, data: 0.003) G_GAN: 1.214 D: 0.801 G_GAN2: 0.524 D2: 0.868 G_L1: 0.939 z_L1: 0.514 kl: 0.029 \n",
      "(epoch: 10, iters: 736, time: 0.045, data: 0.002) G_GAN: 0.901 D: 0.926 G_GAN2: 0.776 D2: 0.523 G_L1: 1.140 z_L1: 0.503 kl: 0.050 \n",
      "(epoch: 10, iters: 836, time: 0.044, data: 0.003) G_GAN: 0.795 D: 0.789 G_GAN2: 1.280 D2: 0.268 G_L1: 0.812 z_L1: 0.271 kl: 0.029 \n",
      "(epoch: 10, iters: 936, time: 0.165, data: 0.002) G_GAN: 1.106 D: 0.427 G_GAN2: 1.167 D2: 0.824 G_L1: 1.373 z_L1: 0.371 kl: 0.013 \n",
      "(epoch: 10, iters: 1036, time: 0.044, data: 0.004) G_GAN: 1.379 D: 0.793 G_GAN2: 1.794 D2: 0.224 G_L1: 1.576 z_L1: 0.407 kl: 0.059 \n",
      "saving the model at the end of epoch 10, iters 10960\n",
      "End of epoch 10 / 40 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 40, time: 0.044, data: 0.002) G_GAN: 0.793 D: 0.414 G_GAN2: 1.484 D2: 0.399 G_L1: 1.075 z_L1: 0.318 kl: 0.030 \n",
      "(epoch: 11, iters: 140, time: 0.046, data: 0.002) G_GAN: 1.718 D: 0.490 G_GAN2: 1.177 D2: 0.316 G_L1: 1.279 z_L1: 0.575 kl: 0.153 \n",
      "(epoch: 11, iters: 240, time: 0.180, data: 0.002) G_GAN: 1.250 D: 0.304 G_GAN2: 1.434 D2: 0.125 G_L1: 1.369 z_L1: 0.508 kl: 0.114 \n",
      "(epoch: 11, iters: 340, time: 0.044, data: 0.003) G_GAN: 1.082 D: 0.793 G_GAN2: 1.590 D2: 0.262 G_L1: 0.805 z_L1: 0.378 kl: 0.019 \n",
      "(epoch: 11, iters: 440, time: 0.045, data: 0.002) G_GAN: 1.314 D: 0.852 G_GAN2: 1.563 D2: 1.331 G_L1: 0.775 z_L1: 0.454 kl: 0.023 \n",
      "(epoch: 11, iters: 540, time: 0.045, data: 0.003) G_GAN: 0.795 D: 0.528 G_GAN2: 1.445 D2: 0.291 G_L1: 1.126 z_L1: 0.498 kl: 0.034 \n",
      "(epoch: 11, iters: 640, time: 0.221, data: 0.002) G_GAN: 1.157 D: 0.501 G_GAN2: 0.833 D2: 0.311 G_L1: 0.858 z_L1: 0.276 kl: 0.028 \n",
      "(epoch: 11, iters: 740, time: 0.051, data: 0.004) G_GAN: 0.915 D: 1.214 G_GAN2: 0.807 D2: 1.242 G_L1: 0.940 z_L1: 0.595 kl: 0.028 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 11, iters: 840, time: 0.038, data: 0.003) G_GAN: 1.118 D: 0.848 G_GAN2: 1.004 D2: 0.327 G_L1: 0.882 z_L1: 0.338 kl: 0.037 \n",
      "(epoch: 11, iters: 940, time: 0.053, data: 0.002) G_GAN: 1.204 D: 0.303 G_GAN2: 1.305 D2: 1.354 G_L1: 0.758 z_L1: 0.470 kl: 0.026 \n",
      "(epoch: 11, iters: 1040, time: 0.191, data: 0.003) G_GAN: 1.103 D: 0.348 G_GAN2: 1.388 D2: 0.539 G_L1: 2.433 z_L1: 0.570 kl: 0.004 \n",
      "End of epoch 11 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 44, time: 0.050, data: 0.004) G_GAN: 1.293 D: 0.388 G_GAN2: 1.982 D2: 0.937 G_L1: 2.682 z_L1: 0.653 kl: 0.228 \n",
      "(epoch: 12, iters: 144, time: 0.057, data: 0.004) G_GAN: 0.827 D: 0.482 G_GAN2: 0.367 D2: 0.894 G_L1: 1.102 z_L1: 0.719 kl: 0.044 \n",
      "(epoch: 12, iters: 244, time: 0.046, data: 0.004) G_GAN: 0.493 D: 1.059 G_GAN2: 1.988 D2: 0.298 G_L1: 1.252 z_L1: 0.375 kl: 0.025 \n",
      "(epoch: 12, iters: 344, time: 0.200, data: 0.003) G_GAN: 1.038 D: 0.514 G_GAN2: 2.080 D2: 0.241 G_L1: 1.317 z_L1: 0.373 kl: 0.014 \n",
      "(epoch: 12, iters: 444, time: 0.046, data: 0.003) G_GAN: 1.124 D: 0.541 G_GAN2: 0.820 D2: 0.468 G_L1: 0.952 z_L1: 0.376 kl: 0.191 \n",
      "(epoch: 12, iters: 544, time: 0.045, data: 0.004) G_GAN: 1.250 D: 0.531 G_GAN2: 1.296 D2: 0.349 G_L1: 0.992 z_L1: 0.329 kl: 0.036 \n",
      "(epoch: 12, iters: 644, time: 0.047, data: 0.002) G_GAN: 1.441 D: 0.349 G_GAN2: 1.240 D2: 0.182 G_L1: 0.989 z_L1: 0.427 kl: 0.020 \n",
      "(epoch: 12, iters: 744, time: 0.183, data: 0.002) G_GAN: 0.621 D: 0.652 G_GAN2: 0.762 D2: 0.850 G_L1: 1.076 z_L1: 0.512 kl: 0.113 \n",
      "(epoch: 12, iters: 844, time: 0.041, data: 0.004) G_GAN: 1.143 D: 0.399 G_GAN2: 0.979 D2: 0.279 G_L1: 1.587 z_L1: 0.589 kl: 0.060 \n",
      "(epoch: 12, iters: 944, time: 0.046, data: 0.002) G_GAN: 0.973 D: 0.541 G_GAN2: 0.752 D2: 0.405 G_L1: 0.802 z_L1: 0.438 kl: 0.241 \n",
      "(epoch: 12, iters: 1044, time: 0.049, data: 0.003) G_GAN: 1.033 D: 0.330 G_GAN2: 0.893 D2: 0.382 G_L1: 2.120 z_L1: 0.327 kl: 0.039 \n",
      "End of epoch 12 / 40 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 48, time: 0.230, data: 0.004) G_GAN: 0.985 D: 0.523 G_GAN2: 0.551 D2: 0.989 G_L1: 1.209 z_L1: 0.714 kl: 0.198 \n",
      "(epoch: 13, iters: 148, time: 0.049, data: 0.003) G_GAN: 1.333 D: 1.025 G_GAN2: 0.361 D2: 0.802 G_L1: 0.749 z_L1: 0.618 kl: 0.022 \n",
      "(epoch: 13, iters: 248, time: 0.043, data: 0.002) G_GAN: 1.815 D: 0.612 G_GAN2: 1.383 D2: 0.190 G_L1: 0.988 z_L1: 0.635 kl: 0.047 \n",
      "(epoch: 13, iters: 348, time: 0.051, data: 0.004) G_GAN: 2.481 D: 0.832 G_GAN2: 0.654 D2: 0.583 G_L1: 1.248 z_L1: 0.437 kl: 0.020 \n",
      "(epoch: 13, iters: 448, time: 0.227, data: 0.003) G_GAN: 1.340 D: 0.193 G_GAN2: 1.350 D2: 0.810 G_L1: 1.484 z_L1: 0.441 kl: 0.024 \n",
      "(epoch: 13, iters: 548, time: 0.041, data: 0.006) G_GAN: 1.564 D: 1.226 G_GAN2: 0.674 D2: 0.621 G_L1: 0.769 z_L1: 0.456 kl: 0.036 \n",
      "(epoch: 13, iters: 648, time: 0.043, data: 0.002) G_GAN: 0.992 D: 0.397 G_GAN2: 1.091 D2: 0.218 G_L1: 1.136 z_L1: 0.529 kl: 0.052 \n",
      "(epoch: 13, iters: 748, time: 0.041, data: 0.002) G_GAN: 1.216 D: 0.348 G_GAN2: 1.997 D2: 0.206 G_L1: 1.992 z_L1: 0.484 kl: 0.034 \n",
      "(epoch: 13, iters: 848, time: 0.220, data: 0.002) G_GAN: 1.054 D: 0.465 G_GAN2: 1.813 D2: 0.198 G_L1: 1.281 z_L1: 0.381 kl: 0.049 \n",
      "(epoch: 13, iters: 948, time: 0.053, data: 0.002) G_GAN: 1.480 D: 0.328 G_GAN2: 0.415 D2: 1.199 G_L1: 1.122 z_L1: 0.386 kl: 0.019 \n",
      "(epoch: 13, iters: 1048, time: 0.044, data: 0.002) G_GAN: 0.683 D: 0.545 G_GAN2: 0.917 D2: 0.948 G_L1: 0.969 z_L1: 0.449 kl: 0.046 \n",
      "End of epoch 13 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 52, time: 0.045, data: 0.002) G_GAN: 1.468 D: 0.482 G_GAN2: 0.975 D2: 0.577 G_L1: 2.261 z_L1: 0.485 kl: 0.061 \n",
      "(epoch: 14, iters: 152, time: 0.226, data: 0.003) G_GAN: 1.230 D: 0.268 G_GAN2: 0.772 D2: 0.530 G_L1: 0.810 z_L1: 0.329 kl: 0.038 \n",
      "(epoch: 14, iters: 252, time: 0.047, data: 0.003) G_GAN: 1.185 D: 0.559 G_GAN2: 1.153 D2: 0.648 G_L1: 1.320 z_L1: 0.560 kl: 0.009 \n",
      "(epoch: 14, iters: 352, time: 0.047, data: 0.002) G_GAN: 1.151 D: 0.367 G_GAN2: 0.961 D2: 0.459 G_L1: 1.102 z_L1: 0.360 kl: 0.039 \n",
      "(epoch: 14, iters: 452, time: 0.045, data: 0.002) G_GAN: 1.444 D: 0.289 G_GAN2: 1.037 D2: 0.260 G_L1: 0.869 z_L1: 0.507 kl: 0.027 \n",
      "(epoch: 14, iters: 552, time: 0.213, data: 0.002) G_GAN: 1.174 D: 0.399 G_GAN2: 1.452 D2: 1.672 G_L1: 0.928 z_L1: 0.459 kl: 0.043 \n",
      "(epoch: 14, iters: 652, time: 0.045, data: 0.003) G_GAN: 1.434 D: 0.343 G_GAN2: 2.019 D2: 1.075 G_L1: 2.790 z_L1: 0.590 kl: 0.230 \n",
      "(epoch: 14, iters: 752, time: 0.049, data: 0.002) G_GAN: 1.424 D: 0.188 G_GAN2: 1.659 D2: 0.851 G_L1: 1.421 z_L1: 0.535 kl: 0.036 \n",
      "(epoch: 14, iters: 852, time: 0.040, data: 0.004) G_GAN: 1.953 D: 0.422 G_GAN2: 0.724 D2: 0.922 G_L1: 0.954 z_L1: 0.457 kl: 0.147 \n",
      "(epoch: 14, iters: 952, time: 0.222, data: 0.002) G_GAN: 1.276 D: 0.427 G_GAN2: 0.522 D2: 0.955 G_L1: 0.946 z_L1: 0.391 kl: 0.031 \n",
      "(epoch: 14, iters: 1052, time: 0.051, data: 0.003) G_GAN: 1.866 D: 0.709 G_GAN2: 0.760 D2: 0.364 G_L1: 0.965 z_L1: 0.512 kl: 0.033 \n",
      "End of epoch 14 / 40 \t Time Taken: 52 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 56, time: 0.041, data: 0.002) G_GAN: 1.195 D: 0.354 G_GAN2: 1.114 D2: 0.577 G_L1: 1.328 z_L1: 0.573 kl: 0.026 \n",
      "(epoch: 15, iters: 156, time: 0.050, data: 0.002) G_GAN: 1.571 D: 0.237 G_GAN2: 2.365 D2: 0.371 G_L1: 1.651 z_L1: 0.253 kl: 0.045 \n",
      "(epoch: 15, iters: 256, time: 0.209, data: 0.002) G_GAN: 1.448 D: 0.322 G_GAN2: 1.281 D2: 0.989 G_L1: 1.253 z_L1: 0.400 kl: 0.029 \n",
      "(epoch: 15, iters: 356, time: 0.048, data: 0.003) G_GAN: 0.679 D: 0.844 G_GAN2: 1.721 D2: 0.211 G_L1: 0.871 z_L1: 0.556 kl: 0.026 \n",
      "(epoch: 15, iters: 456, time: 0.045, data: 0.002) G_GAN: 1.402 D: 0.224 G_GAN2: 1.952 D2: 0.101 G_L1: 0.583 z_L1: 0.900 kl: 0.226 \n",
      "(epoch: 15, iters: 556, time: 0.045, data: 0.003) G_GAN: 0.577 D: 0.580 G_GAN2: 1.083 D2: 0.832 G_L1: 1.084 z_L1: 0.527 kl: 0.082 \n",
      "(epoch: 15, iters: 656, time: 0.203, data: 0.003) G_GAN: 1.631 D: 1.279 G_GAN2: 1.167 D2: 0.159 G_L1: 0.840 z_L1: 0.483 kl: 0.031 \n",
      "(epoch: 15, iters: 756, time: 0.051, data: 0.003) G_GAN: 1.019 D: 0.582 G_GAN2: 1.240 D2: 0.208 G_L1: 1.804 z_L1: 0.413 kl: 0.063 \n",
      "(epoch: 15, iters: 856, time: 0.040, data: 0.002) G_GAN: 0.978 D: 0.477 G_GAN2: 1.009 D2: 0.546 G_L1: 1.328 z_L1: 0.405 kl: 0.025 \n",
      "(epoch: 15, iters: 956, time: 0.048, data: 0.002) G_GAN: 1.055 D: 0.469 G_GAN2: 0.760 D2: 0.398 G_L1: 0.902 z_L1: 0.448 kl: 0.040 \n",
      "(epoch: 15, iters: 1056, time: 0.187, data: 0.003) G_GAN: 1.922 D: 0.889 G_GAN2: 0.911 D2: 0.483 G_L1: 0.862 z_L1: 0.546 kl: 0.099 \n",
      "saving the model at the end of epoch 15, iters 16440\n",
      "End of epoch 15 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 60, time: 0.051, data: 0.003) G_GAN: 0.975 D: 0.305 G_GAN2: 1.015 D2: 0.232 G_L1: 2.013 z_L1: 0.500 kl: 0.081 \n",
      "(epoch: 16, iters: 160, time: 0.039, data: 0.002) G_GAN: 0.978 D: 0.885 G_GAN2: 2.028 D2: 0.146 G_L1: 0.906 z_L1: 0.372 kl: 0.028 \n",
      "(epoch: 16, iters: 260, time: 0.045, data: 0.002) G_GAN: 1.574 D: 0.877 G_GAN2: 0.942 D2: 0.386 G_L1: 0.818 z_L1: 0.442 kl: 0.072 \n",
      "(epoch: 16, iters: 360, time: 0.226, data: 0.002) G_GAN: 1.029 D: 0.250 G_GAN2: 0.465 D2: 0.951 G_L1: 1.226 z_L1: 0.508 kl: 0.033 \n",
      "(epoch: 16, iters: 460, time: 0.041, data: 0.003) G_GAN: 1.770 D: 0.178 G_GAN2: 1.415 D2: 0.212 G_L1: 1.149 z_L1: 0.552 kl: 0.020 \n",
      "(epoch: 16, iters: 560, time: 0.049, data: 0.002) G_GAN: 0.836 D: 0.399 G_GAN2: 1.130 D2: 0.968 G_L1: 1.204 z_L1: 0.659 kl: 0.033 \n",
      "(epoch: 16, iters: 660, time: 0.047, data: 0.002) G_GAN: 0.844 D: 0.368 G_GAN2: 0.381 D2: 1.237 G_L1: 1.355 z_L1: 0.382 kl: 0.038 \n",
      "(epoch: 16, iters: 760, time: 0.205, data: 0.002) G_GAN: 0.880 D: 0.752 G_GAN2: 0.800 D2: 0.526 G_L1: 0.740 z_L1: 0.387 kl: 0.026 \n",
      "(epoch: 16, iters: 860, time: 0.064, data: 0.003) G_GAN: 1.922 D: 0.273 G_GAN2: 1.106 D2: 0.559 G_L1: 1.108 z_L1: 0.856 kl: 0.083 \n",
      "(epoch: 16, iters: 960, time: 0.050, data: 0.003) G_GAN: 0.964 D: 0.304 G_GAN2: 1.154 D2: 0.532 G_L1: 1.116 z_L1: 0.345 kl: 0.178 \n",
      "(epoch: 16, iters: 1060, time: 0.051, data: 0.002) G_GAN: 1.604 D: 0.723 G_GAN2: 0.805 D2: 2.022 G_L1: 1.193 z_L1: 0.541 kl: 0.031 \n",
      "End of epoch 16 / 40 \t Time Taken: 50 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 64, time: 0.215, data: 0.003) G_GAN: 1.724 D: 0.165 G_GAN2: 1.780 D2: 0.417 G_L1: 1.145 z_L1: 0.741 kl: 0.030 \n",
      "(epoch: 17, iters: 164, time: 0.049, data: 0.005) G_GAN: 1.187 D: 0.302 G_GAN2: 1.130 D2: 0.203 G_L1: 0.846 z_L1: 0.776 kl: 0.291 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 17, iters: 264, time: 0.057, data: 0.002) G_GAN: 1.611 D: 0.415 G_GAN2: 0.894 D2: 0.945 G_L1: 1.393 z_L1: 0.365 kl: 0.027 \n",
      "(epoch: 17, iters: 364, time: 0.049, data: 0.003) G_GAN: 0.972 D: 0.454 G_GAN2: 1.058 D2: 0.377 G_L1: 0.951 z_L1: 0.424 kl: 0.025 \n",
      "(epoch: 17, iters: 464, time: 0.177, data: 0.002) G_GAN: 0.863 D: 0.834 G_GAN2: 1.140 D2: 1.155 G_L1: 1.715 z_L1: 0.680 kl: 0.019 \n",
      "(epoch: 17, iters: 564, time: 0.044, data: 0.003) G_GAN: 1.296 D: 0.463 G_GAN2: 1.162 D2: 0.266 G_L1: 2.083 z_L1: 0.568 kl: 0.018 \n",
      "(epoch: 17, iters: 664, time: 0.055, data: 0.004) G_GAN: 1.313 D: 0.193 G_GAN2: 1.183 D2: 0.958 G_L1: 1.375 z_L1: 0.312 kl: 0.041 \n",
      "(epoch: 17, iters: 764, time: 0.051, data: 0.004) G_GAN: 1.283 D: 0.457 G_GAN2: 1.816 D2: 0.204 G_L1: 1.066 z_L1: 0.601 kl: 0.101 \n",
      "(epoch: 17, iters: 864, time: 0.217, data: 0.004) G_GAN: 1.690 D: 0.235 G_GAN2: 1.197 D2: 0.601 G_L1: 0.838 z_L1: 0.776 kl: 0.035 \n",
      "(epoch: 17, iters: 964, time: 0.044, data: 0.005) G_GAN: 1.171 D: 0.224 G_GAN2: 0.635 D2: 0.526 G_L1: 2.103 z_L1: 0.463 kl: 0.049 \n",
      "(epoch: 17, iters: 1064, time: 0.047, data: 0.002) G_GAN: 1.817 D: 0.328 G_GAN2: 0.851 D2: 0.419 G_L1: 1.056 z_L1: 0.831 kl: 0.042 \n",
      "End of epoch 17 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 68, time: 0.057, data: 0.003) G_GAN: 1.292 D: 0.857 G_GAN2: 0.778 D2: 1.138 G_L1: 0.996 z_L1: 0.621 kl: 0.046 \n",
      "(epoch: 18, iters: 168, time: 0.240, data: 0.005) G_GAN: 1.215 D: 0.372 G_GAN2: 1.388 D2: 1.397 G_L1: 0.802 z_L1: 0.390 kl: 0.033 \n",
      "(epoch: 18, iters: 268, time: 0.052, data: 0.003) G_GAN: 1.138 D: 0.306 G_GAN2: 1.134 D2: 0.229 G_L1: 0.893 z_L1: 0.633 kl: 0.048 \n",
      "(epoch: 18, iters: 368, time: 0.048, data: 0.002) G_GAN: 1.256 D: 0.550 G_GAN2: 0.703 D2: 0.768 G_L1: 0.750 z_L1: 0.573 kl: 0.212 \n",
      "(epoch: 18, iters: 468, time: 0.048, data: 0.003) G_GAN: 1.092 D: 0.359 G_GAN2: 1.073 D2: 0.243 G_L1: 0.875 z_L1: 0.472 kl: 0.081 \n",
      "(epoch: 18, iters: 568, time: 0.171, data: 0.002) G_GAN: 1.601 D: 0.110 G_GAN2: 1.686 D2: 1.985 G_L1: 0.702 z_L1: 0.219 kl: 0.203 \n",
      "(epoch: 18, iters: 668, time: 0.049, data: 0.004) G_GAN: 0.642 D: 0.692 G_GAN2: 1.275 D2: 1.033 G_L1: 2.061 z_L1: 0.887 kl: 0.090 \n",
      "(epoch: 18, iters: 768, time: 0.040, data: 0.003) G_GAN: 1.166 D: 0.519 G_GAN2: 1.010 D2: 0.300 G_L1: 0.920 z_L1: 0.648 kl: 0.041 \n",
      "(epoch: 18, iters: 868, time: 0.047, data: 0.002) G_GAN: 1.216 D: 0.303 G_GAN2: 1.438 D2: 0.482 G_L1: 1.051 z_L1: 0.357 kl: 0.044 \n",
      "(epoch: 18, iters: 968, time: 0.175, data: 0.003) G_GAN: 1.493 D: 0.234 G_GAN2: 1.677 D2: 0.227 G_L1: 2.432 z_L1: 0.620 kl: 0.063 \n",
      "(epoch: 18, iters: 1068, time: 0.050, data: 0.002) G_GAN: 1.113 D: 0.663 G_GAN2: 0.758 D2: 1.004 G_L1: 0.893 z_L1: 0.538 kl: 0.040 \n",
      "End of epoch 18 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 72, time: 0.049, data: 0.002) G_GAN: 1.278 D: 0.560 G_GAN2: 1.209 D2: 0.237 G_L1: 1.074 z_L1: 0.588 kl: 0.089 \n",
      "(epoch: 19, iters: 172, time: 0.044, data: 0.002) G_GAN: 0.769 D: 0.664 G_GAN2: 1.929 D2: 1.135 G_L1: 1.152 z_L1: 0.320 kl: 0.047 \n",
      "(epoch: 19, iters: 272, time: 0.213, data: 0.002) G_GAN: 1.112 D: 0.460 G_GAN2: 1.152 D2: 0.229 G_L1: 1.203 z_L1: 0.458 kl: 0.034 \n",
      "saving the latest model (epoch 19, total_iters 20000)\n",
      "(epoch: 19, iters: 372, time: 0.061, data: 0.002) G_GAN: 2.626 D: 0.447 G_GAN2: 1.450 D2: 0.151 G_L1: 1.765 z_L1: 0.616 kl: 0.036 \n",
      "(epoch: 19, iters: 472, time: 0.052, data: 0.002) G_GAN: 1.213 D: 0.188 G_GAN2: 0.797 D2: 0.433 G_L1: 1.108 z_L1: 0.567 kl: 0.041 \n",
      "(epoch: 19, iters: 572, time: 0.045, data: 0.002) G_GAN: 1.809 D: 0.345 G_GAN2: 1.421 D2: 0.887 G_L1: 1.005 z_L1: 0.741 kl: 0.048 \n",
      "(epoch: 19, iters: 672, time: 0.209, data: 0.002) G_GAN: 0.748 D: 0.652 G_GAN2: 1.068 D2: 0.609 G_L1: 0.771 z_L1: 0.390 kl: 0.031 \n",
      "(epoch: 19, iters: 772, time: 0.048, data: 0.003) G_GAN: 1.108 D: 0.480 G_GAN2: 0.837 D2: 0.368 G_L1: 1.000 z_L1: 0.224 kl: 0.109 \n",
      "(epoch: 19, iters: 872, time: 0.043, data: 0.002) G_GAN: 1.474 D: 1.073 G_GAN2: 1.258 D2: 0.970 G_L1: 0.819 z_L1: 0.702 kl: 0.053 \n",
      "(epoch: 19, iters: 972, time: 0.054, data: 0.002) G_GAN: 1.495 D: 0.133 G_GAN2: 0.568 D2: 0.531 G_L1: 1.798 z_L1: 0.438 kl: 0.027 \n",
      "(epoch: 19, iters: 1072, time: 0.209, data: 0.003) G_GAN: 0.776 D: 0.497 G_GAN2: 1.334 D2: 0.602 G_L1: 0.953 z_L1: 0.530 kl: 0.065 \n",
      "End of epoch 19 / 40 \t Time Taken: 56 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 76, time: 0.046, data: 0.004) G_GAN: 1.653 D: 0.691 G_GAN2: 0.729 D2: 0.647 G_L1: 0.826 z_L1: 0.559 kl: 0.045 \n",
      "(epoch: 20, iters: 176, time: 0.050, data: 0.002) G_GAN: 1.345 D: 0.276 G_GAN2: 0.783 D2: 1.852 G_L1: 0.833 z_L1: 0.628 kl: 0.186 \n",
      "(epoch: 20, iters: 276, time: 0.046, data: 0.002) G_GAN: 0.773 D: 0.815 G_GAN2: 1.187 D2: 0.439 G_L1: 1.441 z_L1: 0.408 kl: 0.055 \n",
      "(epoch: 20, iters: 376, time: 0.225, data: 0.003) G_GAN: 1.125 D: 0.330 G_GAN2: 0.866 D2: 0.312 G_L1: 0.967 z_L1: 0.525 kl: 0.039 \n",
      "(epoch: 20, iters: 476, time: 0.058, data: 0.002) G_GAN: 0.758 D: 0.577 G_GAN2: 1.658 D2: 0.267 G_L1: 0.754 z_L1: 0.517 kl: 0.031 \n",
      "(epoch: 20, iters: 576, time: 0.044, data: 0.002) G_GAN: 1.076 D: 0.374 G_GAN2: 0.926 D2: 0.465 G_L1: 1.176 z_L1: 0.339 kl: 0.029 \n",
      "(epoch: 20, iters: 676, time: 0.050, data: 0.002) G_GAN: 1.655 D: 0.311 G_GAN2: 1.042 D2: 0.916 G_L1: 0.806 z_L1: 0.490 kl: 0.034 \n",
      "(epoch: 20, iters: 776, time: 0.191, data: 0.002) G_GAN: 1.403 D: 0.134 G_GAN2: 1.274 D2: 0.851 G_L1: 1.332 z_L1: 0.419 kl: 0.032 \n",
      "(epoch: 20, iters: 876, time: 0.043, data: 0.003) G_GAN: 1.619 D: 0.262 G_GAN2: 0.631 D2: 1.307 G_L1: 0.871 z_L1: 0.529 kl: 0.027 \n",
      "(epoch: 20, iters: 976, time: 0.054, data: 0.002) G_GAN: 1.204 D: 1.060 G_GAN2: 0.478 D2: 0.713 G_L1: 0.740 z_L1: 0.528 kl: 0.155 \n",
      "(epoch: 20, iters: 1076, time: 0.046, data: 0.003) G_GAN: 0.871 D: 0.343 G_GAN2: 1.666 D2: 0.098 G_L1: 1.215 z_L1: 0.606 kl: 0.038 \n",
      "saving the model at the end of epoch 20, iters 21920\n",
      "End of epoch 20 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0001905\n",
      "(epoch: 21, iters: 80, time: 0.187, data: 0.002) G_GAN: 1.543 D: 0.324 G_GAN2: 0.832 D2: 0.489 G_L1: 0.834 z_L1: 0.410 kl: 0.042 \n",
      "(epoch: 21, iters: 180, time: 0.052, data: 0.004) G_GAN: 1.025 D: 0.633 G_GAN2: 1.984 D2: 0.108 G_L1: 0.981 z_L1: 0.657 kl: 0.042 \n",
      "(epoch: 21, iters: 280, time: 0.043, data: 0.003) G_GAN: 1.549 D: 0.140 G_GAN2: 0.960 D2: 1.305 G_L1: 1.030 z_L1: 0.465 kl: 0.041 \n",
      "(epoch: 21, iters: 380, time: 0.044, data: 0.003) G_GAN: 0.575 D: 0.531 G_GAN2: 0.598 D2: 0.589 G_L1: 2.035 z_L1: 0.546 kl: 0.069 \n",
      "(epoch: 21, iters: 480, time: 0.184, data: 0.002) G_GAN: 1.408 D: 0.188 G_GAN2: 0.836 D2: 0.382 G_L1: 3.159 z_L1: 0.317 kl: 0.028 \n",
      "(epoch: 21, iters: 580, time: 0.048, data: 0.003) G_GAN: 1.161 D: 0.231 G_GAN2: 2.279 D2: 0.092 G_L1: 0.969 z_L1: 0.354 kl: 0.024 \n",
      "(epoch: 21, iters: 680, time: 0.050, data: 0.003) G_GAN: 1.601 D: 0.213 G_GAN2: 0.807 D2: 0.628 G_L1: 1.435 z_L1: 0.389 kl: 0.040 \n",
      "(epoch: 21, iters: 780, time: 0.051, data: 0.003) G_GAN: 1.443 D: 0.167 G_GAN2: 0.928 D2: 0.839 G_L1: 1.311 z_L1: 0.709 kl: 0.048 \n",
      "(epoch: 21, iters: 880, time: 0.188, data: 0.002) G_GAN: 1.681 D: 0.765 G_GAN2: 0.989 D2: 0.381 G_L1: 1.608 z_L1: 0.525 kl: 0.077 \n",
      "(epoch: 21, iters: 980, time: 0.046, data: 0.002) G_GAN: 1.476 D: 0.317 G_GAN2: 1.087 D2: 1.104 G_L1: 1.228 z_L1: 0.696 kl: 0.077 \n",
      "(epoch: 21, iters: 1080, time: 0.043, data: 0.003) G_GAN: 1.948 D: 0.364 G_GAN2: 1.396 D2: 0.099 G_L1: 2.095 z_L1: 0.604 kl: 0.263 \n",
      "End of epoch 21 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001810\n",
      "(epoch: 22, iters: 84, time: 0.051, data: 0.003) G_GAN: 1.178 D: 0.246 G_GAN2: 0.982 D2: 0.458 G_L1: 1.896 z_L1: 0.585 kl: 0.131 \n",
      "(epoch: 22, iters: 184, time: 0.195, data: 0.002) G_GAN: 1.333 D: 0.335 G_GAN2: 1.291 D2: 1.023 G_L1: 1.149 z_L1: 0.314 kl: 0.049 \n",
      "(epoch: 22, iters: 284, time: 0.043, data: 0.002) G_GAN: 1.698 D: 0.073 G_GAN2: 0.795 D2: 0.645 G_L1: 1.104 z_L1: 0.389 kl: 0.077 \n",
      "(epoch: 22, iters: 384, time: 0.043, data: 0.005) G_GAN: 1.487 D: 0.124 G_GAN2: 1.348 D2: 0.111 G_L1: 1.291 z_L1: 0.478 kl: 0.052 \n",
      "(epoch: 22, iters: 484, time: 0.043, data: 0.002) G_GAN: 0.878 D: 0.598 G_GAN2: 0.985 D2: 1.118 G_L1: 1.383 z_L1: 0.525 kl: 0.065 \n",
      "(epoch: 22, iters: 584, time: 0.186, data: 0.002) G_GAN: 1.155 D: 0.413 G_GAN2: 1.144 D2: 0.818 G_L1: 1.618 z_L1: 0.509 kl: 0.073 \n",
      "(epoch: 22, iters: 684, time: 0.046, data: 0.003) G_GAN: 1.005 D: 0.302 G_GAN2: 0.451 D2: 0.708 G_L1: 0.820 z_L1: 0.796 kl: 0.092 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 22, iters: 784, time: 0.044, data: 0.002) G_GAN: 1.090 D: 0.766 G_GAN2: 0.486 D2: 2.201 G_L1: 1.614 z_L1: 0.293 kl: 0.068 \n",
      "(epoch: 22, iters: 884, time: 0.050, data: 0.003) G_GAN: 1.290 D: 0.349 G_GAN2: 0.904 D2: 1.388 G_L1: 2.390 z_L1: 0.426 kl: 0.054 \n",
      "(epoch: 22, iters: 984, time: 0.207, data: 0.002) G_GAN: 0.995 D: 0.336 G_GAN2: 0.869 D2: 0.361 G_L1: 1.318 z_L1: 0.465 kl: 0.070 \n",
      "(epoch: 22, iters: 1084, time: 0.041, data: 0.003) G_GAN: 1.463 D: 0.189 G_GAN2: 0.973 D2: 0.964 G_L1: 1.200 z_L1: 0.593 kl: 0.058 \n",
      "End of epoch 22 / 40 \t Time Taken: 55 sec\n",
      "learning rate = 0.0001714\n",
      "(epoch: 23, iters: 88, time: 0.050, data: 0.003) G_GAN: 1.765 D: 0.799 G_GAN2: 0.850 D2: 1.131 G_L1: 1.018 z_L1: 0.673 kl: 0.197 \n",
      "(epoch: 23, iters: 188, time: 0.051, data: 0.002) G_GAN: 1.161 D: 0.272 G_GAN2: 1.095 D2: 0.202 G_L1: 0.990 z_L1: 0.447 kl: 0.066 \n",
      "(epoch: 23, iters: 288, time: 0.199, data: 0.004) G_GAN: 1.222 D: 0.188 G_GAN2: 1.165 D2: 0.168 G_L1: 1.356 z_L1: 0.514 kl: 0.057 \n",
      "(epoch: 23, iters: 388, time: 0.047, data: 0.003) G_GAN: 1.100 D: 0.982 G_GAN2: 2.029 D2: 0.056 G_L1: 0.862 z_L1: 0.378 kl: 0.075 \n",
      "(epoch: 23, iters: 488, time: 0.048, data: 0.003) G_GAN: 1.048 D: 0.390 G_GAN2: 1.061 D2: 0.568 G_L1: 0.890 z_L1: 0.535 kl: 0.067 \n",
      "(epoch: 23, iters: 588, time: 0.044, data: 0.002) G_GAN: 1.018 D: 0.774 G_GAN2: 0.929 D2: 1.263 G_L1: 0.882 z_L1: 0.569 kl: 0.127 \n",
      "(epoch: 23, iters: 688, time: 0.183, data: 0.003) G_GAN: 1.342 D: 0.215 G_GAN2: 0.902 D2: 1.354 G_L1: 2.094 z_L1: 0.588 kl: 0.106 \n",
      "(epoch: 23, iters: 788, time: 0.051, data: 0.002) G_GAN: 0.795 D: 0.709 G_GAN2: 1.144 D2: 0.436 G_L1: 0.809 z_L1: 0.525 kl: 0.118 \n",
      "(epoch: 23, iters: 888, time: 0.047, data: 0.002) G_GAN: 1.186 D: 0.243 G_GAN2: 1.356 D2: 0.108 G_L1: 1.816 z_L1: 0.850 kl: 0.344 \n",
      "(epoch: 23, iters: 988, time: 0.048, data: 0.003) G_GAN: 0.666 D: 0.576 G_GAN2: 0.903 D2: 0.294 G_L1: 1.122 z_L1: 0.577 kl: 0.101 \n",
      "(epoch: 23, iters: 1088, time: 0.217, data: 0.003) G_GAN: 1.636 D: 0.937 G_GAN2: 0.884 D2: 0.277 G_L1: 1.599 z_L1: 0.444 kl: 0.089 \n",
      "End of epoch 23 / 40 \t Time Taken: 52 sec\n",
      "learning rate = 0.0001619\n",
      "(epoch: 24, iters: 92, time: 0.053, data: 0.003) G_GAN: 1.470 D: 0.390 G_GAN2: 0.894 D2: 0.504 G_L1: 0.826 z_L1: 0.827 kl: 0.075 \n",
      "(epoch: 24, iters: 192, time: 0.054, data: 0.003) G_GAN: 1.343 D: 0.226 G_GAN2: 1.647 D2: 0.096 G_L1: 1.305 z_L1: 0.449 kl: 0.078 \n",
      "(epoch: 24, iters: 292, time: 0.044, data: 0.004) G_GAN: 1.587 D: 0.245 G_GAN2: 1.374 D2: 0.165 G_L1: 1.336 z_L1: 0.501 kl: 0.070 \n",
      "(epoch: 24, iters: 392, time: 0.189, data: 0.002) G_GAN: 1.721 D: 0.146 G_GAN2: 1.438 D2: 0.994 G_L1: 1.741 z_L1: 0.858 kl: 0.124 \n",
      "(epoch: 24, iters: 492, time: 0.051, data: 0.002) G_GAN: 0.936 D: 0.578 G_GAN2: 0.492 D2: 1.037 G_L1: 2.588 z_L1: 0.406 kl: 0.094 \n",
      "(epoch: 24, iters: 592, time: 0.054, data: 0.004) G_GAN: 1.291 D: 0.492 G_GAN2: 1.486 D2: 0.851 G_L1: 0.768 z_L1: 0.530 kl: 0.074 \n",
      "(epoch: 24, iters: 692, time: 0.048, data: 0.002) G_GAN: 1.454 D: 0.264 G_GAN2: 0.540 D2: 1.178 G_L1: 2.116 z_L1: 0.604 kl: 0.129 \n",
      "(epoch: 24, iters: 792, time: 0.199, data: 0.002) G_GAN: 0.764 D: 0.425 G_GAN2: 1.162 D2: 1.270 G_L1: 1.402 z_L1: 0.608 kl: 0.058 \n",
      "(epoch: 24, iters: 892, time: 0.051, data: 0.002) G_GAN: 1.126 D: 0.309 G_GAN2: 1.127 D2: 0.614 G_L1: 1.232 z_L1: 0.575 kl: 0.054 \n",
      "(epoch: 24, iters: 992, time: 0.044, data: 0.003) G_GAN: 1.647 D: 0.287 G_GAN2: 1.112 D2: 0.956 G_L1: 0.721 z_L1: 0.468 kl: 0.074 \n",
      "(epoch: 24, iters: 1092, time: 0.050, data: 0.002) G_GAN: 1.207 D: 0.243 G_GAN2: 0.863 D2: 0.985 G_L1: 1.638 z_L1: 0.332 kl: 0.064 \n",
      "End of epoch 24 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001524\n",
      "(epoch: 25, iters: 96, time: 0.207, data: 0.003) G_GAN: 1.304 D: 0.204 G_GAN2: 0.811 D2: 0.695 G_L1: 2.168 z_L1: 0.547 kl: 0.060 \n",
      "(epoch: 25, iters: 196, time: 0.044, data: 0.004) G_GAN: 1.807 D: 0.128 G_GAN2: 1.197 D2: 0.638 G_L1: 1.807 z_L1: 0.471 kl: 0.060 \n",
      "(epoch: 25, iters: 296, time: 0.051, data: 0.002) G_GAN: 1.434 D: 0.225 G_GAN2: 1.121 D2: 0.455 G_L1: 1.742 z_L1: 0.472 kl: 0.033 \n",
      "(epoch: 25, iters: 396, time: 0.049, data: 0.002) G_GAN: 1.525 D: 0.313 G_GAN2: 1.572 D2: 0.113 G_L1: 1.594 z_L1: 0.328 kl: 0.052 \n",
      "(epoch: 25, iters: 496, time: 0.250, data: 0.004) G_GAN: 1.770 D: 1.215 G_GAN2: 1.052 D2: 0.212 G_L1: 0.731 z_L1: 0.515 kl: 0.029 \n",
      "(epoch: 25, iters: 596, time: 0.043, data: 0.003) G_GAN: 1.245 D: 0.381 G_GAN2: 1.003 D2: 0.299 G_L1: 0.856 z_L1: 0.600 kl: 0.101 \n",
      "(epoch: 25, iters: 696, time: 0.050, data: 0.002) G_GAN: 1.379 D: 0.231 G_GAN2: 0.485 D2: 0.909 G_L1: 1.898 z_L1: 0.389 kl: 0.022 \n",
      "(epoch: 25, iters: 796, time: 0.045, data: 0.002) G_GAN: 0.653 D: 0.657 G_GAN2: 1.005 D2: 0.236 G_L1: 1.718 z_L1: 0.585 kl: 0.022 \n",
      "(epoch: 25, iters: 896, time: 0.220, data: 0.003) G_GAN: 0.638 D: 0.547 G_GAN2: 2.390 D2: 0.589 G_L1: 1.450 z_L1: 0.571 kl: 0.049 \n",
      "(epoch: 25, iters: 996, time: 0.047, data: 0.004) G_GAN: 1.293 D: 0.547 G_GAN2: 1.318 D2: 0.259 G_L1: 0.834 z_L1: 0.733 kl: 0.034 \n",
      "(epoch: 25, iters: 1096, time: 0.049, data: 0.003) G_GAN: 0.749 D: 0.964 G_GAN2: 0.625 D2: 0.474 G_L1: 3.084 z_L1: 0.399 kl: 0.008 \n",
      "saving the model at the end of epoch 25, iters 27400\n",
      "End of epoch 25 / 40 \t Time Taken: 57 sec\n",
      "learning rate = 0.0001429\n",
      "(epoch: 26, iters: 100, time: 0.049, data: 0.829) G_GAN: 1.284 D: 0.199 G_GAN2: 1.580 D2: 0.100 G_L1: 0.865 z_L1: 0.381 kl: 0.027 \n",
      "(epoch: 26, iters: 200, time: 0.193, data: 0.002) G_GAN: 1.930 D: 0.184 G_GAN2: 0.743 D2: 0.458 G_L1: 1.809 z_L1: 0.600 kl: 0.153 \n",
      "(epoch: 26, iters: 300, time: 0.049, data: 0.002) G_GAN: 1.087 D: 0.477 G_GAN2: 0.835 D2: 0.347 G_L1: 2.036 z_L1: 0.501 kl: 0.025 \n",
      "(epoch: 26, iters: 400, time: 0.044, data: 0.003) G_GAN: 0.869 D: 0.463 G_GAN2: 1.404 D2: 0.345 G_L1: 0.801 z_L1: 0.691 kl: 0.058 \n",
      "(epoch: 26, iters: 500, time: 0.041, data: 0.002) G_GAN: 0.864 D: 0.312 G_GAN2: 1.040 D2: 0.212 G_L1: 1.354 z_L1: 0.469 kl: 0.085 \n",
      "(epoch: 26, iters: 600, time: 0.213, data: 0.002) G_GAN: 1.721 D: 0.073 G_GAN2: 0.754 D2: 0.421 G_L1: 1.067 z_L1: 0.597 kl: 0.060 \n",
      "(epoch: 26, iters: 700, time: 0.049, data: 0.003) G_GAN: 1.093 D: 0.976 G_GAN2: 0.987 D2: 0.245 G_L1: 1.368 z_L1: 0.500 kl: 0.041 \n",
      "(epoch: 26, iters: 800, time: 0.055, data: 0.005) G_GAN: 1.243 D: 0.232 G_GAN2: 1.237 D2: 0.955 G_L1: 0.841 z_L1: 0.757 kl: 0.052 \n",
      "(epoch: 26, iters: 900, time: 0.048, data: 0.002) G_GAN: 1.450 D: 0.569 G_GAN2: 0.994 D2: 0.463 G_L1: 1.294 z_L1: 0.511 kl: 0.032 \n",
      "(epoch: 26, iters: 1000, time: 0.201, data: 0.003) G_GAN: 1.273 D: 0.647 G_GAN2: 1.287 D2: 0.180 G_L1: 0.793 z_L1: 0.322 kl: 0.072 \n",
      "End of epoch 26 / 40 \t Time Taken: 55 sec\n",
      "learning rate = 0.0001333\n",
      "(epoch: 27, iters: 4, time: 0.046, data: 0.003) G_GAN: 1.445 D: 0.729 G_GAN2: 2.353 D2: 0.099 G_L1: 1.947 z_L1: 0.446 kl: 0.037 \n",
      "(epoch: 27, iters: 104, time: 0.047, data: 0.001) G_GAN: 0.910 D: 0.551 G_GAN2: 0.844 D2: 0.284 G_L1: 2.091 z_L1: 0.526 kl: 0.101 \n",
      "(epoch: 27, iters: 204, time: 0.045, data: 0.002) G_GAN: 0.821 D: 0.343 G_GAN2: 0.776 D2: 0.432 G_L1: 2.016 z_L1: 0.462 kl: 0.095 \n",
      "(epoch: 27, iters: 304, time: 0.239, data: 0.002) G_GAN: 1.223 D: 0.204 G_GAN2: 0.349 D2: 0.792 G_L1: 1.809 z_L1: 0.412 kl: 0.058 \n",
      "(epoch: 27, iters: 404, time: 0.052, data: 0.002) G_GAN: 0.957 D: 0.266 G_GAN2: 1.690 D2: 0.154 G_L1: 2.369 z_L1: 0.336 kl: 0.145 \n",
      "(epoch: 27, iters: 504, time: 0.053, data: 0.003) G_GAN: 1.171 D: 1.495 G_GAN2: 1.059 D2: 0.249 G_L1: 1.412 z_L1: 0.521 kl: 0.051 \n",
      "(epoch: 27, iters: 604, time: 0.051, data: 0.002) G_GAN: 1.219 D: 0.184 G_GAN2: 1.688 D2: 0.656 G_L1: 1.289 z_L1: 0.432 kl: 0.055 \n",
      "(epoch: 27, iters: 704, time: 0.190, data: 0.004) G_GAN: 1.215 D: 1.236 G_GAN2: 1.445 D2: 0.163 G_L1: 1.057 z_L1: 0.471 kl: 0.058 \n",
      "(epoch: 27, iters: 804, time: 0.046, data: 0.003) G_GAN: 1.310 D: 0.387 G_GAN2: 0.941 D2: 0.343 G_L1: 0.949 z_L1: 0.560 kl: 0.097 \n",
      "(epoch: 27, iters: 904, time: 0.046, data: 0.002) G_GAN: 1.193 D: 0.409 G_GAN2: 1.239 D2: 0.224 G_L1: 0.734 z_L1: 0.582 kl: 0.068 \n",
      "(epoch: 27, iters: 1004, time: 0.050, data: 0.003) G_GAN: 1.346 D: 0.107 G_GAN2: 1.365 D2: 1.030 G_L1: 1.575 z_L1: 0.486 kl: 0.042 \n",
      "End of epoch 27 / 40 \t Time Taken: 55 sec\n",
      "learning rate = 0.0001238\n",
      "(epoch: 28, iters: 8, time: 0.318, data: 0.003) G_GAN: 1.713 D: 0.053 G_GAN2: 0.626 D2: 1.203 G_L1: 2.026 z_L1: 0.455 kl: 0.141 \n",
      "(epoch: 28, iters: 108, time: 0.060, data: 0.005) G_GAN: 1.614 D: 0.070 G_GAN2: 0.960 D2: 0.271 G_L1: 2.712 z_L1: 0.446 kl: 0.078 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 28, iters: 208, time: 0.051, data: 0.005) G_GAN: 1.418 D: 0.124 G_GAN2: 0.977 D2: 0.449 G_L1: 0.879 z_L1: 0.452 kl: 0.010 \n",
      "(epoch: 28, iters: 308, time: 0.060, data: 0.004) G_GAN: 1.167 D: 0.299 G_GAN2: 1.559 D2: 0.098 G_L1: 1.240 z_L1: 0.483 kl: 0.033 \n",
      "(epoch: 28, iters: 408, time: 0.223, data: 0.004) G_GAN: 0.859 D: 0.297 G_GAN2: 1.262 D2: 0.192 G_L1: 1.372 z_L1: 0.336 kl: 0.025 \n",
      "saving the latest model (epoch 28, total_iters 30000)\n",
      "(epoch: 28, iters: 508, time: 0.045, data: 0.003) G_GAN: 0.798 D: 0.420 G_GAN2: 0.897 D2: 0.522 G_L1: 1.035 z_L1: 0.520 kl: 0.027 \n",
      "(epoch: 28, iters: 608, time: 0.050, data: 0.003) G_GAN: 1.245 D: 0.573 G_GAN2: 0.879 D2: 1.028 G_L1: 0.835 z_L1: 0.492 kl: 0.025 \n",
      "(epoch: 28, iters: 708, time: 0.059, data: 0.003) G_GAN: 0.575 D: 0.682 G_GAN2: 0.831 D2: 0.334 G_L1: 1.478 z_L1: 0.508 kl: 0.028 \n",
      "(epoch: 28, iters: 808, time: 0.214, data: 0.004) G_GAN: 1.451 D: 0.390 G_GAN2: 1.518 D2: 0.341 G_L1: 1.252 z_L1: 0.463 kl: 0.018 \n",
      "(epoch: 28, iters: 908, time: 0.047, data: 0.004) G_GAN: 1.316 D: 0.354 G_GAN2: 0.784 D2: 0.363 G_L1: 1.233 z_L1: 0.605 kl: 0.059 \n",
      "(epoch: 28, iters: 1008, time: 0.045, data: 0.002) G_GAN: 1.452 D: 0.305 G_GAN2: 1.514 D2: 0.306 G_L1: 1.323 z_L1: 0.374 kl: 0.048 \n",
      "End of epoch 28 / 40 \t Time Taken: 60 sec\n",
      "learning rate = 0.0001143\n",
      "(epoch: 29, iters: 12, time: 0.043, data: 0.003) G_GAN: 1.672 D: 0.262 G_GAN2: 1.163 D2: 0.139 G_L1: 0.941 z_L1: 0.577 kl: 0.067 \n",
      "(epoch: 29, iters: 112, time: 0.213, data: 0.002) G_GAN: 1.050 D: 0.425 G_GAN2: 0.962 D2: 0.604 G_L1: 0.969 z_L1: 0.421 kl: 0.082 \n",
      "(epoch: 29, iters: 212, time: 0.050, data: 0.004) G_GAN: 1.336 D: 0.186 G_GAN2: 1.005 D2: 0.509 G_L1: 1.688 z_L1: 0.653 kl: 0.088 \n",
      "(epoch: 29, iters: 312, time: 0.046, data: 0.002) G_GAN: 1.553 D: 0.430 G_GAN2: 1.014 D2: 0.811 G_L1: 1.733 z_L1: 0.718 kl: 0.076 \n",
      "(epoch: 29, iters: 412, time: 0.044, data: 0.002) G_GAN: 1.298 D: 0.496 G_GAN2: 1.156 D2: 0.654 G_L1: 0.909 z_L1: 0.304 kl: 0.028 \n",
      "(epoch: 29, iters: 512, time: 0.213, data: 0.003) G_GAN: 0.918 D: 0.302 G_GAN2: 1.249 D2: 0.156 G_L1: 1.631 z_L1: 0.474 kl: 0.051 \n",
      "(epoch: 29, iters: 612, time: 0.048, data: 0.002) G_GAN: 1.450 D: 0.169 G_GAN2: 0.908 D2: 0.634 G_L1: 1.626 z_L1: 0.580 kl: 0.047 \n",
      "(epoch: 29, iters: 712, time: 0.045, data: 0.003) G_GAN: 1.038 D: 0.462 G_GAN2: 1.159 D2: 0.740 G_L1: 1.519 z_L1: 0.396 kl: 0.010 \n",
      "(epoch: 29, iters: 812, time: 0.046, data: 0.002) G_GAN: 1.023 D: 0.977 G_GAN2: 0.766 D2: 0.435 G_L1: 0.842 z_L1: 0.583 kl: 0.038 \n",
      "(epoch: 29, iters: 912, time: 0.224, data: 0.003) G_GAN: 0.823 D: 0.362 G_GAN2: 1.204 D2: 0.144 G_L1: 1.541 z_L1: 0.259 kl: 0.044 \n",
      "(epoch: 29, iters: 1012, time: 0.047, data: 0.004) G_GAN: 1.221 D: 0.619 G_GAN2: 0.693 D2: 1.022 G_L1: 1.017 z_L1: 0.569 kl: 0.010 \n",
      "End of epoch 29 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0001048\n",
      "(epoch: 30, iters: 16, time: 0.054, data: 0.002) G_GAN: 1.239 D: 0.163 G_GAN2: 1.168 D2: 0.857 G_L1: 1.957 z_L1: 0.375 kl: 0.028 \n",
      "(epoch: 30, iters: 116, time: 0.056, data: 0.004) G_GAN: 0.968 D: 0.275 G_GAN2: 1.469 D2: 0.088 G_L1: 2.449 z_L1: 0.488 kl: 0.041 \n",
      "(epoch: 30, iters: 216, time: 0.198, data: 0.002) G_GAN: 0.913 D: 0.294 G_GAN2: 0.900 D2: 0.416 G_L1: 1.236 z_L1: 0.292 kl: 0.020 \n",
      "(epoch: 30, iters: 316, time: 0.045, data: 0.002) G_GAN: 0.942 D: 0.391 G_GAN2: 1.164 D2: 0.576 G_L1: 1.188 z_L1: 0.362 kl: 0.023 \n",
      "(epoch: 30, iters: 416, time: 0.047, data: 0.002) G_GAN: 1.769 D: 0.107 G_GAN2: 0.767 D2: 0.590 G_L1: 0.978 z_L1: 0.196 kl: 0.018 \n",
      "(epoch: 30, iters: 516, time: 0.051, data: 0.002) G_GAN: 1.114 D: 0.683 G_GAN2: 1.323 D2: 1.509 G_L1: 0.836 z_L1: 0.620 kl: 0.025 \n",
      "(epoch: 30, iters: 616, time: 0.247, data: 0.002) G_GAN: 1.099 D: 0.508 G_GAN2: 0.833 D2: 0.328 G_L1: 1.581 z_L1: 0.575 kl: 0.074 \n",
      "(epoch: 30, iters: 716, time: 0.049, data: 0.003) G_GAN: 1.195 D: 0.618 G_GAN2: 0.477 D2: 0.621 G_L1: 0.829 z_L1: 0.514 kl: 0.055 \n",
      "(epoch: 30, iters: 816, time: 0.044, data: 0.004) G_GAN: 1.256 D: 0.278 G_GAN2: 0.984 D2: 0.239 G_L1: 1.638 z_L1: 0.590 kl: 0.069 \n",
      "(epoch: 30, iters: 916, time: 0.047, data: 0.003) G_GAN: 1.840 D: 0.077 G_GAN2: 0.997 D2: 0.217 G_L1: 1.712 z_L1: 1.052 kl: 0.178 \n",
      "(epoch: 30, iters: 1016, time: 0.230, data: 0.002) G_GAN: 1.134 D: 0.287 G_GAN2: 1.325 D2: 0.186 G_L1: 1.180 z_L1: 0.577 kl: 0.064 \n",
      "saving the model at the end of epoch 30, iters 32880\n",
      "End of epoch 30 / 40 \t Time Taken: 57 sec\n",
      "learning rate = 0.0000952\n",
      "(epoch: 31, iters: 20, time: 0.041, data: 0.004) G_GAN: 1.328 D: 0.170 G_GAN2: 0.881 D2: 0.321 G_L1: 1.373 z_L1: 0.633 kl: 0.062 \n",
      "(epoch: 31, iters: 120, time: 0.051, data: 0.002) G_GAN: 1.269 D: 0.228 G_GAN2: 1.693 D2: 0.255 G_L1: 2.032 z_L1: 0.806 kl: 0.053 \n",
      "(epoch: 31, iters: 220, time: 0.048, data: 0.004) G_GAN: 0.671 D: 0.564 G_GAN2: 0.942 D2: 0.730 G_L1: 2.099 z_L1: 0.403 kl: 0.066 \n",
      "(epoch: 31, iters: 320, time: 0.194, data: 0.003) G_GAN: 1.120 D: 0.285 G_GAN2: 0.726 D2: 0.400 G_L1: 2.215 z_L1: 0.745 kl: 0.181 \n",
      "(epoch: 31, iters: 420, time: 0.058, data: 0.003) G_GAN: 1.581 D: 0.456 G_GAN2: 1.287 D2: 0.341 G_L1: 0.943 z_L1: 0.385 kl: 0.080 \n",
      "(epoch: 31, iters: 520, time: 0.049, data: 0.002) G_GAN: 0.999 D: 0.587 G_GAN2: 1.270 D2: 0.148 G_L1: 0.793 z_L1: 0.706 kl: 0.071 \n",
      "(epoch: 31, iters: 620, time: 0.050, data: 0.002) G_GAN: 1.395 D: 0.141 G_GAN2: 1.222 D2: 0.247 G_L1: 2.323 z_L1: 0.366 kl: 0.064 \n",
      "(epoch: 31, iters: 720, time: 0.203, data: 0.002) G_GAN: 1.332 D: 0.317 G_GAN2: 1.365 D2: 0.098 G_L1: 0.895 z_L1: 0.659 kl: 0.065 \n",
      "(epoch: 31, iters: 820, time: 0.048, data: 0.003) G_GAN: 0.657 D: 1.447 G_GAN2: 1.352 D2: 0.751 G_L1: 1.287 z_L1: 0.488 kl: 0.063 \n",
      "(epoch: 31, iters: 920, time: 0.050, data: 0.004) G_GAN: 1.331 D: 0.573 G_GAN2: 1.153 D2: 0.805 G_L1: 1.145 z_L1: 0.678 kl: 0.075 \n",
      "(epoch: 31, iters: 1020, time: 0.056, data: 0.002) G_GAN: 1.242 D: 0.467 G_GAN2: 0.882 D2: 0.274 G_L1: 0.731 z_L1: 0.458 kl: 0.073 \n",
      "End of epoch 31 / 40 \t Time Taken: 58 sec\n",
      "learning rate = 0.0000857\n",
      "(epoch: 32, iters: 24, time: 0.202, data: 0.002) G_GAN: 0.849 D: 0.402 G_GAN2: 0.597 D2: 0.480 G_L1: 2.075 z_L1: 0.563 kl: 0.052 \n",
      "(epoch: 32, iters: 124, time: 0.050, data: 0.004) G_GAN: 1.240 D: 0.302 G_GAN2: 0.705 D2: 0.884 G_L1: 1.503 z_L1: 0.611 kl: 0.048 \n",
      "(epoch: 32, iters: 224, time: 0.043, data: 0.002) G_GAN: 1.106 D: 0.294 G_GAN2: 1.185 D2: 1.088 G_L1: 2.357 z_L1: 0.578 kl: 0.078 \n",
      "(epoch: 32, iters: 324, time: 0.045, data: 0.002) G_GAN: 1.353 D: 0.314 G_GAN2: 1.160 D2: 1.266 G_L1: 1.723 z_L1: 0.720 kl: 0.056 \n",
      "(epoch: 32, iters: 424, time: 0.236, data: 0.003) G_GAN: 1.448 D: 0.857 G_GAN2: 1.561 D2: 0.071 G_L1: 1.018 z_L1: 0.611 kl: 0.058 \n",
      "(epoch: 32, iters: 524, time: 0.047, data: 0.003) G_GAN: 1.107 D: 0.223 G_GAN2: 0.523 D2: 0.604 G_L1: 1.696 z_L1: 0.519 kl: 0.162 \n",
      "(epoch: 32, iters: 624, time: 0.051, data: 0.002) G_GAN: 1.012 D: 0.759 G_GAN2: 1.190 D2: 0.137 G_L1: 1.118 z_L1: 0.581 kl: 0.055 \n",
      "(epoch: 32, iters: 724, time: 0.050, data: 0.002) G_GAN: 1.823 D: 0.044 G_GAN2: 0.989 D2: 0.710 G_L1: 1.679 z_L1: 0.645 kl: 0.197 \n",
      "(epoch: 32, iters: 824, time: 0.235, data: 0.004) G_GAN: 1.359 D: 0.248 G_GAN2: 1.665 D2: 0.058 G_L1: 1.227 z_L1: 0.760 kl: 0.073 \n",
      "(epoch: 32, iters: 924, time: 0.046, data: 0.005) G_GAN: 1.295 D: 0.195 G_GAN2: 1.179 D2: 0.925 G_L1: 2.440 z_L1: 0.505 kl: 0.137 \n",
      "(epoch: 32, iters: 1024, time: 0.047, data: 0.003) G_GAN: 0.977 D: 0.651 G_GAN2: 1.158 D2: 1.000 G_L1: 1.812 z_L1: 0.616 kl: 0.091 \n",
      "End of epoch 32 / 40 \t Time Taken: 52 sec\n",
      "learning rate = 0.0000762\n",
      "(epoch: 33, iters: 28, time: 0.044, data: 0.002) G_GAN: 1.375 D: 0.223 G_GAN2: 1.457 D2: 0.078 G_L1: 1.160 z_L1: 0.649 kl: 0.068 \n",
      "(epoch: 33, iters: 128, time: 0.215, data: 0.002) G_GAN: 1.438 D: 0.352 G_GAN2: 1.517 D2: 0.081 G_L1: 1.612 z_L1: 0.468 kl: 0.048 \n",
      "(epoch: 33, iters: 228, time: 0.052, data: 0.004) G_GAN: 1.509 D: 0.085 G_GAN2: 0.755 D2: 0.347 G_L1: 2.009 z_L1: 0.527 kl: 0.115 \n",
      "(epoch: 33, iters: 328, time: 0.044, data: 0.004) G_GAN: 1.781 D: 0.264 G_GAN2: 0.821 D2: 0.454 G_L1: 1.590 z_L1: 0.646 kl: 0.053 \n",
      "(epoch: 33, iters: 428, time: 0.049, data: 0.002) G_GAN: 1.416 D: 0.165 G_GAN2: 1.265 D2: 0.298 G_L1: 1.899 z_L1: 0.621 kl: 0.119 \n",
      "(epoch: 33, iters: 528, time: 0.236, data: 0.002) G_GAN: 1.378 D: 0.251 G_GAN2: 1.029 D2: 0.232 G_L1: 1.899 z_L1: 0.725 kl: 0.076 \n",
      "(epoch: 33, iters: 628, time: 0.047, data: 0.006) G_GAN: 1.134 D: 0.332 G_GAN2: 1.655 D2: 0.043 G_L1: 0.939 z_L1: 0.863 kl: 0.071 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 33, iters: 728, time: 0.041, data: 0.002) G_GAN: 1.641 D: 0.514 G_GAN2: 1.813 D2: 0.104 G_L1: 1.027 z_L1: 0.478 kl: 0.073 \n",
      "(epoch: 33, iters: 828, time: 0.049, data: 0.002) G_GAN: 1.597 D: 0.147 G_GAN2: 1.304 D2: 0.718 G_L1: 1.622 z_L1: 0.563 kl: 0.070 \n",
      "(epoch: 33, iters: 928, time: 0.228, data: 0.002) G_GAN: 1.391 D: 0.460 G_GAN2: 1.098 D2: 0.299 G_L1: 1.341 z_L1: 0.399 kl: 0.059 \n",
      "(epoch: 33, iters: 1028, time: 0.043, data: 0.004) G_GAN: 1.053 D: 0.304 G_GAN2: 0.969 D2: 0.841 G_L1: 0.836 z_L1: 0.743 kl: 0.074 \n",
      "End of epoch 33 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000667\n",
      "(epoch: 34, iters: 32, time: 0.048, data: 0.002) G_GAN: 1.314 D: 1.070 G_GAN2: 1.325 D2: 0.830 G_L1: 0.941 z_L1: 0.409 kl: 0.076 \n",
      "(epoch: 34, iters: 132, time: 0.052, data: 0.002) G_GAN: 1.171 D: 0.178 G_GAN2: 0.864 D2: 1.749 G_L1: 1.334 z_L1: 0.449 kl: 0.064 \n",
      "(epoch: 34, iters: 232, time: 0.245, data: 0.002) G_GAN: 1.044 D: 0.374 G_GAN2: 0.974 D2: 0.265 G_L1: 1.231 z_L1: 0.506 kl: 0.092 \n",
      "(epoch: 34, iters: 332, time: 0.045, data: 0.003) G_GAN: 1.052 D: 0.266 G_GAN2: 0.717 D2: 0.434 G_L1: 1.497 z_L1: 0.368 kl: 0.165 \n",
      "(epoch: 34, iters: 432, time: 0.046, data: 0.003) G_GAN: 1.377 D: 0.467 G_GAN2: 0.866 D2: 0.859 G_L1: 1.205 z_L1: 0.623 kl: 0.117 \n",
      "(epoch: 34, iters: 532, time: 0.048, data: 0.001) G_GAN: 1.589 D: 0.101 G_GAN2: 0.951 D2: 0.342 G_L1: 1.765 z_L1: 0.545 kl: 0.164 \n",
      "(epoch: 34, iters: 632, time: 0.226, data: 0.002) G_GAN: 1.169 D: 0.836 G_GAN2: 1.649 D2: 0.057 G_L1: 0.937 z_L1: 0.446 kl: 0.075 \n",
      "(epoch: 34, iters: 732, time: 0.041, data: 0.003) G_GAN: 1.224 D: 0.339 G_GAN2: 1.245 D2: 0.232 G_L1: 0.897 z_L1: 0.788 kl: 0.099 \n",
      "(epoch: 34, iters: 832, time: 0.053, data: 0.002) G_GAN: 1.308 D: 0.165 G_GAN2: 1.334 D2: 0.573 G_L1: 1.952 z_L1: 0.548 kl: 0.044 \n",
      "(epoch: 34, iters: 932, time: 0.044, data: 0.003) G_GAN: 1.503 D: 0.213 G_GAN2: 1.255 D2: 0.105 G_L1: 1.067 z_L1: 0.466 kl: 0.073 \n",
      "(epoch: 34, iters: 1032, time: 0.204, data: 0.003) G_GAN: 1.404 D: 0.221 G_GAN2: 1.474 D2: 0.123 G_L1: 1.716 z_L1: 0.403 kl: 0.110 \n",
      "End of epoch 34 / 40 \t Time Taken: 50 sec\n",
      "learning rate = 0.0000571\n",
      "(epoch: 35, iters: 36, time: 0.051, data: 0.004) G_GAN: 1.367 D: 0.278 G_GAN2: 1.188 D2: 0.180 G_L1: 1.306 z_L1: 0.535 kl: 0.064 \n",
      "(epoch: 35, iters: 136, time: 0.045, data: 0.003) G_GAN: 1.769 D: 0.385 G_GAN2: 0.711 D2: 0.940 G_L1: 1.303 z_L1: 0.537 kl: 0.084 \n",
      "(epoch: 35, iters: 236, time: 0.046, data: 0.004) G_GAN: 1.320 D: 1.524 G_GAN2: 0.722 D2: 0.384 G_L1: 0.969 z_L1: 0.495 kl: 0.076 \n",
      "(epoch: 35, iters: 336, time: 0.251, data: 0.003) G_GAN: 1.201 D: 0.197 G_GAN2: 0.934 D2: 0.254 G_L1: 0.773 z_L1: 0.407 kl: 0.075 \n",
      "(epoch: 35, iters: 436, time: 0.045, data: 0.002) G_GAN: 1.202 D: 1.424 G_GAN2: 1.418 D2: 0.076 G_L1: 0.975 z_L1: 0.672 kl: 0.083 \n",
      "(epoch: 35, iters: 536, time: 0.045, data: 0.002) G_GAN: 0.740 D: 1.083 G_GAN2: 0.864 D2: 0.285 G_L1: 1.012 z_L1: 0.615 kl: 0.069 \n",
      "(epoch: 35, iters: 636, time: 0.045, data: 0.002) G_GAN: 1.436 D: 0.296 G_GAN2: 1.175 D2: 0.139 G_L1: 1.479 z_L1: 0.554 kl: 0.058 \n",
      "(epoch: 35, iters: 736, time: 0.221, data: 0.003) G_GAN: 1.632 D: 0.135 G_GAN2: 1.520 D2: 0.596 G_L1: 1.857 z_L1: 0.650 kl: 0.078 \n",
      "(epoch: 35, iters: 836, time: 0.043, data: 0.002) G_GAN: 1.387 D: 0.249 G_GAN2: 1.052 D2: 0.287 G_L1: 2.014 z_L1: 0.360 kl: 0.058 \n",
      "(epoch: 35, iters: 936, time: 0.044, data: 0.002) G_GAN: 1.267 D: 0.995 G_GAN2: 0.997 D2: 0.228 G_L1: 0.846 z_L1: 0.648 kl: 0.064 \n",
      "(epoch: 35, iters: 1036, time: 0.059, data: 0.002) G_GAN: 1.179 D: 0.197 G_GAN2: 1.179 D2: 0.135 G_L1: 1.081 z_L1: 0.524 kl: 0.079 \n",
      "saving the model at the end of epoch 35, iters 38360\n",
      "End of epoch 35 / 40 \t Time Taken: 55 sec\n",
      "learning rate = 0.0000476\n",
      "(epoch: 36, iters: 40, time: 0.245, data: 0.002) G_GAN: 1.336 D: 0.144 G_GAN2: 1.185 D2: 0.577 G_L1: 1.823 z_L1: 0.797 kl: 0.078 \n",
      "(epoch: 36, iters: 140, time: 0.044, data: 0.003) G_GAN: 1.068 D: 0.440 G_GAN2: 1.872 D2: 0.724 G_L1: 1.037 z_L1: 0.420 kl: 0.233 \n",
      "(epoch: 36, iters: 240, time: 0.045, data: 0.002) G_GAN: 0.855 D: 0.458 G_GAN2: 1.239 D2: 0.164 G_L1: 0.839 z_L1: 0.565 kl: 0.073 \n",
      "(epoch: 36, iters: 340, time: 0.046, data: 0.002) G_GAN: 1.122 D: 0.189 G_GAN2: 0.995 D2: 1.682 G_L1: 0.936 z_L1: 0.523 kl: 0.297 \n",
      "(epoch: 36, iters: 440, time: 0.230, data: 0.002) G_GAN: 1.626 D: 0.098 G_GAN2: 0.951 D2: 0.398 G_L1: 1.058 z_L1: 0.473 kl: 0.072 \n",
      "(epoch: 36, iters: 540, time: 0.042, data: 0.004) G_GAN: 0.919 D: 0.525 G_GAN2: 1.091 D2: 0.501 G_L1: 1.135 z_L1: 0.508 kl: 0.087 \n",
      "(epoch: 36, iters: 640, time: 0.054, data: 0.002) G_GAN: 1.363 D: 0.278 G_GAN2: 1.312 D2: 0.376 G_L1: 0.975 z_L1: 0.636 kl: 0.081 \n",
      "(epoch: 36, iters: 740, time: 0.043, data: 0.002) G_GAN: 1.069 D: 0.240 G_GAN2: 1.369 D2: 0.151 G_L1: 1.515 z_L1: 0.505 kl: 0.055 \n",
      "(epoch: 36, iters: 840, time: 0.233, data: 0.002) G_GAN: 1.133 D: 0.256 G_GAN2: 1.327 D2: 0.160 G_L1: 1.661 z_L1: 0.491 kl: 0.055 \n",
      "(epoch: 36, iters: 940, time: 0.040, data: 0.002) G_GAN: 1.226 D: 0.212 G_GAN2: 1.258 D2: 0.535 G_L1: 0.999 z_L1: 0.355 kl: 0.283 \n",
      "(epoch: 36, iters: 1040, time: 0.041, data: 0.004) G_GAN: 1.160 D: 0.343 G_GAN2: 1.131 D2: 0.168 G_L1: 0.851 z_L1: 0.654 kl: 0.062 \n",
      "End of epoch 36 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000381\n",
      "(epoch: 37, iters: 44, time: 0.038, data: 0.002) G_GAN: 1.382 D: 0.402 G_GAN2: 1.277 D2: 0.101 G_L1: 1.516 z_L1: 0.674 kl: 0.059 \n",
      "(epoch: 37, iters: 144, time: 0.231, data: 0.002) G_GAN: 1.178 D: 0.551 G_GAN2: 1.303 D2: 1.037 G_L1: 0.892 z_L1: 0.423 kl: 0.070 \n",
      "(epoch: 37, iters: 244, time: 0.054, data: 0.002) G_GAN: 1.237 D: 0.472 G_GAN2: 1.221 D2: 0.238 G_L1: 0.959 z_L1: 0.564 kl: 0.070 \n",
      "(epoch: 37, iters: 344, time: 0.040, data: 0.002) G_GAN: 1.264 D: 0.574 G_GAN2: 0.634 D2: 0.453 G_L1: 2.442 z_L1: 0.385 kl: 0.069 \n",
      "(epoch: 37, iters: 444, time: 0.050, data: 0.002) G_GAN: 2.060 D: 0.238 G_GAN2: 1.140 D2: 0.644 G_L1: 0.869 z_L1: 0.569 kl: 0.078 \n",
      "(epoch: 37, iters: 544, time: 0.218, data: 0.002) G_GAN: 0.763 D: 0.761 G_GAN2: 0.972 D2: 0.253 G_L1: 1.469 z_L1: 0.616 kl: 0.071 \n",
      "saving the latest model (epoch 37, total_iters 40000)\n",
      "(epoch: 37, iters: 644, time: 0.050, data: 0.002) G_GAN: 1.222 D: 0.142 G_GAN2: 1.316 D2: 0.112 G_L1: 1.255 z_L1: 0.636 kl: 0.083 \n",
      "(epoch: 37, iters: 744, time: 0.052, data: 0.002) G_GAN: 1.406 D: 0.116 G_GAN2: 1.346 D2: 0.158 G_L1: 1.149 z_L1: 0.360 kl: 0.076 \n",
      "(epoch: 37, iters: 844, time: 0.042, data: 0.002) G_GAN: 1.096 D: 0.587 G_GAN2: 1.084 D2: 0.195 G_L1: 0.852 z_L1: 0.546 kl: 0.080 \n",
      "(epoch: 37, iters: 944, time: 0.211, data: 0.002) G_GAN: 1.048 D: 0.274 G_GAN2: 1.076 D2: 0.178 G_L1: 2.298 z_L1: 0.469 kl: 0.103 \n",
      "(epoch: 37, iters: 1044, time: 0.045, data: 0.004) G_GAN: 1.455 D: 0.162 G_GAN2: 1.421 D2: 0.685 G_L1: 1.556 z_L1: 0.349 kl: 0.074 \n",
      "End of epoch 37 / 40 \t Time Taken: 55 sec\n",
      "learning rate = 0.0000286\n",
      "(epoch: 38, iters: 48, time: 0.038, data: 0.002) G_GAN: 1.447 D: 0.229 G_GAN2: 0.835 D2: 0.318 G_L1: 0.942 z_L1: 0.596 kl: 0.073 \n",
      "(epoch: 38, iters: 148, time: 0.055, data: 0.002) G_GAN: 1.179 D: 0.191 G_GAN2: 0.785 D2: 0.953 G_L1: 1.761 z_L1: 0.658 kl: 0.051 \n",
      "(epoch: 38, iters: 248, time: 0.234, data: 0.002) G_GAN: 1.516 D: 0.424 G_GAN2: 1.384 D2: 1.021 G_L1: 1.053 z_L1: 0.381 kl: 0.073 \n",
      "(epoch: 38, iters: 348, time: 0.045, data: 0.002) G_GAN: 1.507 D: 0.340 G_GAN2: 1.214 D2: 0.171 G_L1: 0.794 z_L1: 0.408 kl: 0.071 \n",
      "(epoch: 38, iters: 448, time: 0.054, data: 0.003) G_GAN: 0.950 D: 0.317 G_GAN2: 1.180 D2: 1.169 G_L1: 1.511 z_L1: 0.457 kl: 0.064 \n",
      "(epoch: 38, iters: 548, time: 0.044, data: 0.002) G_GAN: 1.421 D: 0.098 G_GAN2: 1.099 D2: 0.183 G_L1: 1.402 z_L1: 0.692 kl: 0.060 \n",
      "(epoch: 38, iters: 648, time: 0.239, data: 0.002) G_GAN: 1.340 D: 0.302 G_GAN2: 0.920 D2: 0.248 G_L1: 1.278 z_L1: 0.530 kl: 0.058 \n",
      "(epoch: 38, iters: 748, time: 0.045, data: 0.003) G_GAN: 1.120 D: 0.162 G_GAN2: 1.129 D2: 0.203 G_L1: 1.424 z_L1: 0.299 kl: 0.249 \n",
      "(epoch: 38, iters: 848, time: 0.040, data: 0.002) G_GAN: 1.334 D: 0.209 G_GAN2: 1.234 D2: 0.123 G_L1: 1.660 z_L1: 0.573 kl: 0.190 \n",
      "(epoch: 38, iters: 948, time: 0.047, data: 0.002) G_GAN: 1.224 D: 0.164 G_GAN2: 1.025 D2: 0.235 G_L1: 1.657 z_L1: 0.413 kl: 0.162 \n",
      "(epoch: 38, iters: 1048, time: 0.243, data: 0.002) G_GAN: 1.425 D: 0.192 G_GAN2: 1.432 D2: 0.111 G_L1: 1.138 z_L1: 0.508 kl: 0.069 \n",
      "End of epoch 38 / 40 \t Time Taken: 53 sec\n",
      "learning rate = 0.0000190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 39, iters: 52, time: 0.043, data: 0.003) G_GAN: 1.744 D: 0.097 G_GAN2: 1.307 D2: 0.110 G_L1: 2.375 z_L1: 0.678 kl: 0.079 \n",
      "(epoch: 39, iters: 152, time: 0.047, data: 0.002) G_GAN: 1.237 D: 0.409 G_GAN2: 1.225 D2: 0.120 G_L1: 0.777 z_L1: 0.647 kl: 0.061 \n",
      "(epoch: 39, iters: 252, time: 0.055, data: 0.003) G_GAN: 1.267 D: 1.657 G_GAN2: 1.072 D2: 1.065 G_L1: 0.835 z_L1: 0.818 kl: 0.065 \n",
      "(epoch: 39, iters: 352, time: 0.240, data: 0.004) G_GAN: 1.194 D: 0.291 G_GAN2: 1.372 D2: 0.473 G_L1: 1.051 z_L1: 0.424 kl: 0.068 \n",
      "(epoch: 39, iters: 452, time: 0.045, data: 0.003) G_GAN: 1.025 D: 0.231 G_GAN2: 1.401 D2: 0.080 G_L1: 1.330 z_L1: 0.896 kl: 0.191 \n",
      "(epoch: 39, iters: 552, time: 0.051, data: 0.002) G_GAN: 1.258 D: 0.393 G_GAN2: 0.811 D2: 0.387 G_L1: 0.909 z_L1: 0.426 kl: 0.074 \n",
      "(epoch: 39, iters: 652, time: 0.049, data: 0.003) G_GAN: 1.262 D: 0.214 G_GAN2: 1.210 D2: 0.151 G_L1: 1.382 z_L1: 0.402 kl: 0.062 \n",
      "(epoch: 39, iters: 752, time: 0.200, data: 0.003) G_GAN: 1.377 D: 0.202 G_GAN2: 1.303 D2: 0.116 G_L1: 2.379 z_L1: 0.635 kl: 0.052 \n",
      "(epoch: 39, iters: 852, time: 0.045, data: 0.004) G_GAN: 0.897 D: 1.134 G_GAN2: 1.126 D2: 0.165 G_L1: 1.126 z_L1: 0.604 kl: 0.075 \n",
      "(epoch: 39, iters: 952, time: 0.046, data: 0.002) G_GAN: 0.988 D: 1.427 G_GAN2: 1.112 D2: 0.632 G_L1: 1.278 z_L1: 0.458 kl: 0.082 \n",
      "(epoch: 39, iters: 1052, time: 0.047, data: 0.002) G_GAN: 1.101 D: 0.251 G_GAN2: 0.835 D2: 0.287 G_L1: 1.872 z_L1: 0.574 kl: 0.124 \n",
      "End of epoch 39 / 40 \t Time Taken: 54 sec\n",
      "learning rate = 0.0000095\n",
      "(epoch: 40, iters: 56, time: 0.228, data: 0.002) G_GAN: 1.305 D: 1.040 G_GAN2: 1.385 D2: 0.343 G_L1: 1.949 z_L1: 0.592 kl: 0.068 \n",
      "(epoch: 40, iters: 156, time: 0.047, data: 0.002) G_GAN: 1.462 D: 0.368 G_GAN2: 0.729 D2: 1.341 G_L1: 1.673 z_L1: 0.375 kl: 0.071 \n",
      "(epoch: 40, iters: 256, time: 0.050, data: 0.002) G_GAN: 1.031 D: 0.275 G_GAN2: 0.970 D2: 1.306 G_L1: 1.869 z_L1: 0.403 kl: 0.151 \n",
      "(epoch: 40, iters: 356, time: 0.042, data: 0.003) G_GAN: 1.443 D: 0.107 G_GAN2: 1.124 D2: 0.582 G_L1: 1.524 z_L1: 0.551 kl: 0.075 \n",
      "(epoch: 40, iters: 456, time: 0.214, data: 0.002) G_GAN: 1.346 D: 0.118 G_GAN2: 1.432 D2: 1.117 G_L1: 1.584 z_L1: 0.577 kl: 0.071 \n",
      "(epoch: 40, iters: 556, time: 0.048, data: 0.002) G_GAN: 1.328 D: 0.196 G_GAN2: 1.203 D2: 1.390 G_L1: 1.558 z_L1: 0.687 kl: 0.077 \n",
      "(epoch: 40, iters: 656, time: 0.045, data: 0.002) G_GAN: 1.307 D: 0.329 G_GAN2: 1.353 D2: 0.878 G_L1: 1.309 z_L1: 0.372 kl: 0.074 \n",
      "(epoch: 40, iters: 756, time: 0.054, data: 0.002) G_GAN: 1.151 D: 0.645 G_GAN2: 1.328 D2: 1.198 G_L1: 0.932 z_L1: 0.485 kl: 0.079 \n",
      "(epoch: 40, iters: 856, time: 0.209, data: 0.003) G_GAN: 1.124 D: 0.304 G_GAN2: 0.855 D2: 0.970 G_L1: 1.421 z_L1: 0.426 kl: 0.143 \n",
      "(epoch: 40, iters: 956, time: 0.052, data: 0.002) G_GAN: 1.174 D: 0.229 G_GAN2: 1.518 D2: 0.125 G_L1: 1.949 z_L1: 0.880 kl: 0.094 \n",
      "(epoch: 40, iters: 1056, time: 0.044, data: 0.002) G_GAN: 1.149 D: 0.186 G_GAN2: 1.797 D2: 0.078 G_L1: 1.270 z_L1: 0.693 kl: 0.171 \n",
      "saving the model at the end of epoch 40, iters 43840\n",
      "End of epoch 40 / 40 \t Time Taken: 56 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)      \n",
    "model.setup(opt)              \n",
    "visualizer = Visualizer(opt) \n",
    "total_iters = 0 \n",
    "losses_data = {}\n",
    "iter_data = []\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):    \n",
    "    epoch_start_time = time.time() \n",
    "    iter_data_time = time.time()   \n",
    "    epoch_iter = 0                  \n",
    "    \n",
    "    for i, data in enumerate(dataset): \n",
    "        iter_start_time = time.time()  \n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        visualizer.reset()\n",
    "        total_iters += opt.batch_size\n",
    "        epoch_iter += opt.batch_size\n",
    "        model.set_input(data)        \n",
    "        if not model.is_train():     \n",
    "            print('skip this batch')\n",
    "            continue\n",
    "        model.optimize_parameters()   \n",
    "\n",
    "        if total_iters % opt.display_freq == 0: \n",
    "            save_result = total_iters % opt.update_html_freq == 0\n",
    "            model.compute_visuals()\n",
    "            visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "        if total_iters % opt.print_freq == 0:   \n",
    "            losses = model.get_current_losses()\n",
    "            t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "            visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "            if opt.display_id > 0:\n",
    "                visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, losses)\n",
    "\n",
    "        if total_iters % opt.save_latest_freq == 0:   \n",
    "            print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "            model.save_networks('latest')\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:              \n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50ddfd",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c15631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestOptions(BaseOptions):\n",
    "    def initialize(self, parser):\n",
    "        BaseOptions.initialize(self, parser)\n",
    "        parser.add_argument('--results_dir', type=str, default='../results/', help='saves results here.')\n",
    "        parser.add_argument('--phase', type=str, default='val', help='train, val, test, etc')\n",
    "        parser.add_argument('--num_test', type=int, default=50, help='how many test images to run')\n",
    "        parser.add_argument('--n_samples', type=int, default=5, help='#samples')\n",
    "        parser.add_argument('--no_encode', action='store_true', help='do not produce encoded image')\n",
    "        parser.add_argument('--sync', action='store_true', help='use the same latent code for different input images')\n",
    "        parser.add_argument('--aspect_ratio', type=float, default=1.0, help='aspect ratio for the results')\n",
    "        parser.add_argument('--eval', action='store_true', help='use eval mode during test time.')\n",
    "\n",
    "        self.isTrain = False\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1861326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_dir = \"real_images\"\n",
    "fake_images_dir = \"fake_images\"\n",
    "\n",
    "os.makedirs(real_images_dir, exist_ok=True)\n",
    "os.makedirs(fake_images_dir, exist_ok=True)\n",
    "def tensor_to_pil(tensor):\n",
    "    return transforms.ToPILImage()(tensor.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b38cd19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 2                             \n",
      "              center_crop: False                         \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "            conditional_D: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/maps               \t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_size: 286                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: bicycle_gan                   \n",
      "                n_samples: 5                             \n",
      "                     name:                               \n",
      "                      ndf: 64                            \n",
      "                      nef: 64                            \n",
      "                     netD: basic_256_multi               \n",
      "                    netD2: basic_256_multi               \n",
      "                     netE: resnet_256                    \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "                       nl: relu                          \n",
      "                no_encode: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                   num_Ds: 2                             \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                       nz: 8                             \n",
      "                output_nc: 3                             \n",
      "                    phase: val                           \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ../results/                   \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     sync: False                         \n",
      "                 upsample: basic                         \n",
      "              use_dropout: False                         \n",
      "                  verbose: False                         \n",
      "                where_add: all                           \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [BiCycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.795 M\n",
      "[Network E] Total number of parameters : 2.590 M\n",
      "-----------------------------------------------\n",
      "Loading model bicycle_gan\n",
      "process input image 000/050\n",
      "process input image 001/050\n",
      "process input image 002/050\n",
      "process input image 003/050\n",
      "process input image 004/050\n",
      "process input image 005/050\n",
      "process input image 006/050\n",
      "process input image 007/050\n",
      "process input image 008/050\n",
      "process input image 009/050\n",
      "process input image 010/050\n",
      "process input image 011/050\n",
      "process input image 012/050\n",
      "process input image 013/050\n",
      "process input image 014/050\n",
      "process input image 015/050\n",
      "process input image 016/050\n",
      "process input image 017/050\n",
      "process input image 018/050\n",
      "process input image 019/050\n",
      "process input image 020/050\n",
      "process input image 021/050\n",
      "process input image 022/050\n",
      "process input image 023/050\n",
      "process input image 024/050\n",
      "process input image 025/050\n",
      "process input image 026/050\n",
      "process input image 027/050\n",
      "process input image 028/050\n",
      "process input image 029/050\n",
      "process input image 030/050\n",
      "process input image 031/050\n",
      "process input image 032/050\n",
      "process input image 033/050\n",
      "process input image 034/050\n",
      "process input image 035/050\n",
      "process input image 036/050\n",
      "process input image 037/050\n",
      "process input image 038/050\n",
      "process input image 039/050\n",
      "process input image 040/050\n",
      "process input image 041/050\n",
      "process input image 042/050\n",
      "process input image 043/050\n",
      "process input image 044/050\n",
      "process input image 045/050\n",
      "process input image 046/050\n",
      "process input image 047/050\n",
      "process input image 048/050\n",
      "process input image 049/050\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "opt = TestOptions().parse()\n",
    "opt.num_threads = 1  \n",
    "opt.batch_size = 1  \n",
    "opt.serial_batches = True\n",
    "\n",
    "# create dataset\n",
    "dataset = create_dataset(opt)\n",
    "model = create_model(opt)\n",
    "model.setup(opt)\n",
    "model.eval()\n",
    "print('Loading model %s' % opt.model)\n",
    "\n",
    "web_dir = os.path.join(opt.results_dir, opt.phase + '_sync' if opt.sync else opt.phase)\n",
    "webpage = html.HTML(web_dir, 'Training = %s, Phase = %s, Class =%s' % (opt.name, opt.phase, opt.name))\n",
    "\n",
    "# sample random z\n",
    "if opt.sync:\n",
    "    z_samples = model.get_z_random(opt.n_samples + 1, opt.nz)\n",
    "\n",
    "# test stage\n",
    "for i, data in enumerate(islice(dataset, opt.num_test)):\n",
    "    model.set_input(data)\n",
    "    print('process input image %3.3d/%3.3d' % (i, opt.num_test))\n",
    "    if not opt.sync:\n",
    "        z_samples = model.get_z_random(opt.n_samples + 1, opt.nz)\n",
    "    for nn in range(opt.n_samples + 1):\n",
    "        encode = nn == 0 and not opt.no_encode\n",
    "        real_A, fake_B, real_B = model.test(z_samples[[nn]], encode=encode)\n",
    "        real_image_path = os.path.join(real_images_dir, f'real_image_{i}.png')\n",
    "        fake_image_path = os.path.join(fake_images_dir, f'fake_image_{i}_{nn}.png')\n",
    "        tensor_to_pil(real_A.squeeze(0)).save(real_image_path)\n",
    "        tensor_to_pil(fake_B.squeeze(0)).save(fake_image_path)\n",
    "        \n",
    "        if nn == 0:\n",
    "            images = [real_A, real_B, fake_B]\n",
    "            names = ['input', 'ground truth', 'encoded']\n",
    "            \n",
    "        else:\n",
    "            images.append(fake_B)\n",
    "            names.append('random_sample%2.2d' % nn)\n",
    "\n",
    "    img_path = 'input_%3.3d' % i\n",
    "    save_images(webpage, images, names, img_path, aspect_ratio=opt.aspect_ratio, width=opt.crop_size)\n",
    "\n",
    "webpage.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cce598",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6eb420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 106.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:01<00:00, 197.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score:  8.63273997616474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fid_value = fid_score.calculate_fid_given_paths([real_images_dir, fake_images_dir],\n",
    "                                                batch_size=opt.batch_size,\n",
    "                                                device='cuda',\n",
    "                                                dims=64)\n",
    "print('FID score: ', fid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd934217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
